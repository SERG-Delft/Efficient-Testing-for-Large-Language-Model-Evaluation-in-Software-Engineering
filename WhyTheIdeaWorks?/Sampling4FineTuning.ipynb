{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ac5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 21854\n",
      "First training example: {'project': 'FFmpeg', 'commit_id': '973b1a6b9070e2bf17d17568cbaf4043ce931f51', 'target': 0, 'func': 'static av_cold int vdadec_init(AVCodecContext *avctx)\\n\\n{\\n\\n    VDADecoderContext *ctx = avctx->priv_data;\\n\\n    struct vda_context *vda_ctx = &ctx->vda_ctx;\\n\\n    OSStatus status;\\n\\n    int ret;\\n\\n\\n\\n    ctx->h264_initialized = 0;\\n\\n\\n\\n    /* init pix_fmts of codec */\\n\\n    if (!ff_h264_vda_decoder.pix_fmts) {\\n\\n        if (kCFCoreFoundationVersionNumber < kCFCoreFoundationVersionNumber10_7)\\n\\n            ff_h264_vda_decoder.pix_fmts = vda_pixfmts_prior_10_7;\\n\\n        else\\n\\n            ff_h264_vda_decoder.pix_fmts = vda_pixfmts;\\n\\n    }\\n\\n\\n\\n    /* init vda */\\n\\n    memset(vda_ctx, 0, sizeof(struct vda_context));\\n\\n    vda_ctx->width = avctx->width;\\n\\n    vda_ctx->height = avctx->height;\\n\\n    vda_ctx->format = \\'avc1\\';\\n\\n    vda_ctx->use_sync_decoding = 1;\\n\\n    vda_ctx->use_ref_buffer = 1;\\n\\n    ctx->pix_fmt = avctx->get_format(avctx, avctx->codec->pix_fmts);\\n\\n    switch (ctx->pix_fmt) {\\n\\n    case AV_PIX_FMT_UYVY422:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'2vuy\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_YUYV422:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'yuvs\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_NV12:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'420v\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_YUV420P:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'y420\\';\\n\\n        break;\\n\\n    default:\\n\\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported pixel format: %d\\\\n\", avctx->pix_fmt);\\n\\n        goto failed;\\n\\n    }\\n\\n    status = ff_vda_create_decoder(vda_ctx,\\n\\n                                   avctx->extradata, avctx->extradata_size);\\n\\n    if (status != kVDADecoderNoErr) {\\n\\n        av_log(avctx, AV_LOG_ERROR,\\n\\n                \"Failed to init VDA decoder: %d.\\\\n\", status);\\n\\n        goto failed;\\n\\n    }\\n\\n    avctx->hwaccel_context = vda_ctx;\\n\\n\\n\\n    /* changes callback functions */\\n\\n    avctx->get_format = get_format;\\n\\n    avctx->get_buffer2 = get_buffer2;\\n\\n#if FF_API_GET_BUFFER\\n\\n    // force the old get_buffer to be empty\\n\\n    avctx->get_buffer = NULL;\\n\\n#endif\\n\\n\\n\\n    /* init H.264 decoder */\\n\\n    ret = ff_h264_decoder.init(avctx);\\n\\n    if (ret < 0) {\\n\\n        av_log(avctx, AV_LOG_ERROR, \"Failed to open H.264 decoder.\\\\n\");\\n\\n        goto failed;\\n\\n    }\\n\\n    ctx->h264_initialized = 1;\\n\\n\\n\\n    return 0;\\n\\n\\n\\nfailed:\\n\\n    vdadec_close(avctx);\\n\\n    return -1;\\n\\n}\\n', 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to read a .jsonl file\n",
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [json.loads(line.strip()) for line in file]\n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "train_data = load_jsonl(\"train.jsonl\")\n",
    "valid_data = load_jsonl(\"valid.jsonl\")\n",
    "test_data = load_jsonl(\"test.jsonl\")\n",
    "\n",
    "# Inspect the first few examples\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"First training example: {train_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f6b0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['project', 'commit_id', 'target', 'func', 'idx'])\n"
     ]
    }
   ],
   "source": [
    "# Print keys of the first sample\n",
    "print(train_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877c6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "{'project': 'FFmpeg', 'commit_id': '973b1a6b9070e2bf17d17568cbaf4043ce931f51', 'target': 0, 'func': 'static av_cold int vdadec_init(AVCodecContext *avctx)\\n\\n{\\n\\n    VDADecoderContext *ctx = avctx->priv_data;\\n\\n    struct vda_context *vda_ctx = &ctx->vda_ctx;\\n\\n    OSStatus status;\\n\\n    int ret;\\n\\n\\n\\n    ctx->h264_initialized = 0;\\n\\n\\n\\n    /* init pix_fmts of codec */\\n\\n    if (!ff_h264_vda_decoder.pix_fmts) {\\n\\n        if (kCFCoreFoundationVersionNumber < kCFCoreFoundationVersionNumber10_7)\\n\\n            ff_h264_vda_decoder.pix_fmts = vda_pixfmts_prior_10_7;\\n\\n        else\\n\\n            ff_h264_vda_decoder.pix_fmts = vda_pixfmts;\\n\\n    }\\n\\n\\n\\n    /* init vda */\\n\\n    memset(vda_ctx, 0, sizeof(struct vda_context));\\n\\n    vda_ctx->width = avctx->width;\\n\\n    vda_ctx->height = avctx->height;\\n\\n    vda_ctx->format = \\'avc1\\';\\n\\n    vda_ctx->use_sync_decoding = 1;\\n\\n    vda_ctx->use_ref_buffer = 1;\\n\\n    ctx->pix_fmt = avctx->get_format(avctx, avctx->codec->pix_fmts);\\n\\n    switch (ctx->pix_fmt) {\\n\\n    case AV_PIX_FMT_UYVY422:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'2vuy\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_YUYV422:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'yuvs\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_NV12:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'420v\\';\\n\\n        break;\\n\\n    case AV_PIX_FMT_YUV420P:\\n\\n        vda_ctx->cv_pix_fmt_type = \\'y420\\';\\n\\n        break;\\n\\n    default:\\n\\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported pixel format: %d\\\\n\", avctx->pix_fmt);\\n\\n        goto failed;\\n\\n    }\\n\\n    status = ff_vda_create_decoder(vda_ctx,\\n\\n                                   avctx->extradata, avctx->extradata_size);\\n\\n    if (status != kVDADecoderNoErr) {\\n\\n        av_log(avctx, AV_LOG_ERROR,\\n\\n                \"Failed to init VDA decoder: %d.\\\\n\", status);\\n\\n        goto failed;\\n\\n    }\\n\\n    avctx->hwaccel_context = vda_ctx;\\n\\n\\n\\n    /* changes callback functions */\\n\\n    avctx->get_format = get_format;\\n\\n    avctx->get_buffer2 = get_buffer2;\\n\\n#if FF_API_GET_BUFFER\\n\\n    // force the old get_buffer to be empty\\n\\n    avctx->get_buffer = NULL;\\n\\n#endif\\n\\n\\n\\n    /* init H.264 decoder */\\n\\n    ret = ff_h264_decoder.init(avctx);\\n\\n    if (ret < 0) {\\n\\n        av_log(avctx, AV_LOG_ERROR, \"Failed to open H.264 decoder.\\\\n\");\\n\\n        goto failed;\\n\\n    }\\n\\n    ctx->h264_initialized = 1;\\n\\n\\n\\n    return 0;\\n\\n\\n\\nfailed:\\n\\n    vdadec_close(avctx);\\n\\n    return -1;\\n\\n}\\n', 'idx': 0}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "{'project': 'FFmpeg', 'commit_id': '321b2a9ded0468670b7678b7c098886930ae16b2', 'target': 0, 'func': 'static int transcode(AVFormatContext **output_files,\\n\\n                     int nb_output_files,\\n\\n                     InputFile *input_files,\\n\\n                     int nb_input_files,\\n\\n                     StreamMap *stream_maps, int nb_stream_maps)\\n\\n{\\n\\n    int ret = 0, i, j, k, n, nb_ostreams = 0, step;\\n\\n\\n\\n    AVFormatContext *is, *os;\\n\\n    AVCodecContext *codec, *icodec;\\n\\n    OutputStream *ost, **ost_table = NULL;\\n\\n    InputStream *ist;\\n\\n    char error[1024];\\n\\n    int key;\\n\\n    int want_sdp = 1;\\n\\n    uint8_t no_packet[MAX_FILES]={0};\\n\\n    int no_packet_count=0;\\n\\n    int nb_frame_threshold[AVMEDIA_TYPE_NB]={0};\\n\\n    int nb_streams[AVMEDIA_TYPE_NB]={0};\\n\\n\\n\\n    if (rate_emu)\\n\\n        for (i = 0; i < nb_input_streams; i++)\\n\\n            input_streams[i].start = av_gettime();\\n\\n\\n\\n    /* output stream init */\\n\\n    nb_ostreams = 0;\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        if (!os->nb_streams && !(os->oformat->flags & AVFMT_NOSTREAMS)) {\\n\\n            av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n            fprintf(stderr, \"Output file #%d does not contain any stream\\\\n\", i);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n        nb_ostreams += os->nb_streams;\\n\\n    }\\n\\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\\n\\n        fprintf(stderr, \"Number of stream maps must match number of output streams\\\\n\");\\n\\n        ret = AVERROR(EINVAL);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    /* Sanity check the mapping args -- do the input files & streams exist? */\\n\\n    for(i=0;i<nb_stream_maps;i++) {\\n\\n        int fi = stream_maps[i].file_index;\\n\\n        int si = stream_maps[i].stream_index;\\n\\n\\n\\n        if (fi < 0 || fi > nb_input_files - 1 ||\\n\\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\\n\\n            fprintf(stderr,\"Could not find input stream #%d.%d\\\\n\", fi, si);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n        fi = stream_maps[i].sync_file_index;\\n\\n        si = stream_maps[i].sync_stream_index;\\n\\n        if (fi < 0 || fi > nb_input_files - 1 ||\\n\\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\\n\\n            fprintf(stderr,\"Could not find sync stream #%d.%d\\\\n\", fi, si);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    ost_table = av_mallocz(sizeof(OutputStream *) * nb_ostreams);\\n\\n    if (!ost_table)\\n\\n        goto fail;\\n\\n\\n\\n    for(k=0;k<nb_output_files;k++) {\\n\\n        os = output_files[k];\\n\\n        for(i=0;i<os->nb_streams;i++,n++) {\\n\\n            nb_streams[os->streams[i]->codec->codec_type]++;\\n\\n        }\\n\\n    }\\n\\n    for(step=1<<30; step; step>>=1){\\n\\n        int found_streams[AVMEDIA_TYPE_NB]={0};\\n\\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\\n\\n            nb_frame_threshold[j] += step;\\n\\n\\n\\n        for(j=0; j<nb_input_streams; j++) {\\n\\n            int skip=0;\\n\\n            ist = &input_streams[j];\\n\\n            if(opt_programid){\\n\\n                int pi,si;\\n\\n                AVFormatContext *f= input_files[ ist->file_index ].ctx;\\n\\n                skip=1;\\n\\n                for(pi=0; pi<f->nb_programs; pi++){\\n\\n                    AVProgram *p= f->programs[pi];\\n\\n                    if(p->id == opt_programid)\\n\\n                        for(si=0; si<p->nb_stream_indexes; si++){\\n\\n                            if(f->streams[ p->stream_index[si] ] == ist->st)\\n\\n                                skip=0;\\n\\n                        }\\n\\n                }\\n\\n            }\\n\\n            if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip\\n\\n                && nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames){\\n\\n                found_streams[ist->st->codec->codec_type]++;\\n\\n            }\\n\\n        }\\n\\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\\n\\n            if(found_streams[j] < nb_streams[j])\\n\\n                nb_frame_threshold[j] -= step;\\n\\n    }\\n\\n    n = 0;\\n\\n    for(k=0;k<nb_output_files;k++) {\\n\\n        os = output_files[k];\\n\\n        for(i=0;i<os->nb_streams;i++,n++) {\\n\\n            int found;\\n\\n            ost = ost_table[n] = output_streams_for_file[k][i];\\n\\n            if (nb_stream_maps > 0) {\\n\\n                ost->source_index = input_files[stream_maps[n].file_index].ist_index +\\n\\n                    stream_maps[n].stream_index;\\n\\n\\n\\n                /* Sanity check that the stream types match */\\n\\n                if (input_streams[ost->source_index].st->codec->codec_type != ost->st->codec->codec_type) {\\n\\n                    int i= ost->file_index;\\n\\n                    av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n                    fprintf(stderr, \"Codec type mismatch for mapping #%d.%d -> #%d.%d\\\\n\",\\n\\n                        stream_maps[n].file_index, stream_maps[n].stream_index,\\n\\n                        ost->file_index, ost->index);\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n\\n\\n            } else {\\n\\n                /* get corresponding input stream index : we select the first one with the right type */\\n\\n                found = 0;\\n\\n                for (j = 0; j < nb_input_streams; j++) {\\n\\n                    int skip=0;\\n\\n                    ist = &input_streams[j];\\n\\n                    if(opt_programid){\\n\\n                        int pi,si;\\n\\n                        AVFormatContext *f = input_files[ist->file_index].ctx;\\n\\n                        skip=1;\\n\\n                        for(pi=0; pi<f->nb_programs; pi++){\\n\\n                            AVProgram *p= f->programs[pi];\\n\\n                            if(p->id == opt_programid)\\n\\n                                for(si=0; si<p->nb_stream_indexes; si++){\\n\\n                                    if(f->streams[ p->stream_index[si] ] == ist->st)\\n\\n                                        skip=0;\\n\\n                                }\\n\\n                        }\\n\\n                    }\\n\\n                    if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip &&\\n\\n                        ist->st->codec->codec_type == ost->st->codec->codec_type &&\\n\\n                        nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames) {\\n\\n                            ost->source_index = j;\\n\\n                            found = 1;\\n\\n                            break;\\n\\n                    }\\n\\n                }\\n\\n\\n\\n                if (!found) {\\n\\n                    if(! opt_programid) {\\n\\n                        /* try again and reuse existing stream */\\n\\n                        for (j = 0; j < nb_input_streams; j++) {\\n\\n                            ist = &input_streams[j];\\n\\n                            if (   ist->st->codec->codec_type == ost->st->codec->codec_type\\n\\n                                && ist->st->discard != AVDISCARD_ALL) {\\n\\n                                ost->source_index = j;\\n\\n                                found = 1;\\n\\n                            }\\n\\n                        }\\n\\n                    }\\n\\n                    if (!found) {\\n\\n                        int i= ost->file_index;\\n\\n                        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n                        fprintf(stderr, \"Could not find input stream matching output stream #%d.%d\\\\n\",\\n\\n                                ost->file_index, ost->index);\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                }\\n\\n            }\\n\\n            ist = &input_streams[ost->source_index];\\n\\n            ist->discard = 0;\\n\\n            ost->sync_ist = (nb_stream_maps > 0) ?\\n\\n                &input_streams[input_files[stream_maps[n].sync_file_index].ist_index +\\n\\n                         stream_maps[n].sync_stream_index] : ist;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* for each output stream, we compute the right encoding parameters */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        os = output_files[ost->file_index];\\n\\n        ist = &input_streams[ost->source_index];\\n\\n\\n\\n        codec = ost->st->codec;\\n\\n        icodec = ist->st->codec;\\n\\n\\n\\n        if (metadata_streams_autocopy)\\n\\n            av_dict_copy(&ost->st->metadata, ist->st->metadata,\\n\\n                         AV_DICT_DONT_OVERWRITE);\\n\\n\\n\\n        ost->st->disposition = ist->st->disposition;\\n\\n        codec->bits_per_raw_sample= icodec->bits_per_raw_sample;\\n\\n        codec->chroma_sample_location = icodec->chroma_sample_location;\\n\\n\\n\\n        if (ost->st->stream_copy) {\\n\\n            uint64_t extra_size = (uint64_t)icodec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE;\\n\\n\\n\\n            if (extra_size > INT_MAX)\\n\\n                goto fail;\\n\\n\\n\\n            /* if stream_copy is selected, no need to decode or encode */\\n\\n            codec->codec_id = icodec->codec_id;\\n\\n            codec->codec_type = icodec->codec_type;\\n\\n\\n\\n            if(!codec->codec_tag){\\n\\n                if(   !os->oformat->codec_tag\\n\\n                   || av_codec_get_id (os->oformat->codec_tag, icodec->codec_tag) == codec->codec_id\\n\\n                   || av_codec_get_tag(os->oformat->codec_tag, icodec->codec_id) <= 0)\\n\\n                    codec->codec_tag = icodec->codec_tag;\\n\\n            }\\n\\n\\n\\n            codec->bit_rate = icodec->bit_rate;\\n\\n            codec->rc_max_rate    = icodec->rc_max_rate;\\n\\n            codec->rc_buffer_size = icodec->rc_buffer_size;\\n\\n            codec->extradata= av_mallocz(extra_size);\\n\\n            if (!codec->extradata)\\n\\n                goto fail;\\n\\n            memcpy(codec->extradata, icodec->extradata, icodec->extradata_size);\\n\\n            codec->extradata_size= icodec->extradata_size;\\n\\n            if(!copy_tb && av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/500){\\n\\n                codec->time_base = icodec->time_base;\\n\\n                codec->time_base.num *= icodec->ticks_per_frame;\\n\\n                av_reduce(&codec->time_base.num, &codec->time_base.den,\\n\\n                          codec->time_base.num, codec->time_base.den, INT_MAX);\\n\\n            }else\\n\\n                codec->time_base = ist->st->time_base;\\n\\n            switch(codec->codec_type) {\\n\\n            case AVMEDIA_TYPE_AUDIO:\\n\\n                if(audio_volume != 256) {\\n\\n                    fprintf(stderr,\"-acodec copy and -vol are incompatible (frames are not decoded)\\\\n\");\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n                codec->channel_layout = icodec->channel_layout;\\n\\n                codec->sample_rate = icodec->sample_rate;\\n\\n                codec->channels = icodec->channels;\\n\\n                codec->frame_size = icodec->frame_size;\\n\\n                codec->audio_service_type = icodec->audio_service_type;\\n\\n                codec->block_align= icodec->block_align;\\n\\n                if(codec->block_align == 1 && codec->codec_id == CODEC_ID_MP3)\\n\\n                    codec->block_align= 0;\\n\\n                if(codec->codec_id == CODEC_ID_AC3)\\n\\n                    codec->block_align= 0;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_VIDEO:\\n\\n                codec->pix_fmt = icodec->pix_fmt;\\n\\n                codec->width = icodec->width;\\n\\n                codec->height = icodec->height;\\n\\n                codec->has_b_frames = icodec->has_b_frames;\\n\\n                if (!codec->sample_aspect_ratio.num) {\\n\\n                    codec->sample_aspect_ratio =\\n\\n                    ost->st->sample_aspect_ratio =\\n\\n                        ist->st->sample_aspect_ratio.num ? ist->st->sample_aspect_ratio :\\n\\n                        ist->st->codec->sample_aspect_ratio.num ?\\n\\n                        ist->st->codec->sample_aspect_ratio : (AVRational){0, 1};\\n\\n                }\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_SUBTITLE:\\n\\n                codec->width = icodec->width;\\n\\n                codec->height = icodec->height;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_DATA:\\n\\n                break;\\n\\n            default:\\n\\n                abort();\\n\\n            }\\n\\n        } else {\\n\\n            if (!ost->enc)\\n\\n                ost->enc = avcodec_find_encoder(ost->st->codec->codec_id);\\n\\n            switch(codec->codec_type) {\\n\\n            case AVMEDIA_TYPE_AUDIO:\\n\\n                ost->fifo= av_fifo_alloc(1024);\\n\\n                if(!ost->fifo)\\n\\n                    goto fail;\\n\\n                ost->reformat_pair = MAKE_SFMT_PAIR(AV_SAMPLE_FMT_NONE,AV_SAMPLE_FMT_NONE);\\n\\n                if (!codec->sample_rate) {\\n\\n                    codec->sample_rate = icodec->sample_rate;\\n\\n                    if (icodec->lowres)\\n\\n                        codec->sample_rate >>= icodec->lowres;\\n\\n                }\\n\\n                choose_sample_rate(ost->st, ost->enc);\\n\\n                codec->time_base = (AVRational){1, codec->sample_rate};\\n\\n                if (codec->sample_fmt == AV_SAMPLE_FMT_NONE)\\n\\n                    codec->sample_fmt = icodec->sample_fmt;\\n\\n                choose_sample_fmt(ost->st, ost->enc);\\n\\n                if (!codec->channels) {\\n\\n                    codec->channels = icodec->channels;\\n\\n                    codec->channel_layout = icodec->channel_layout;\\n\\n                }\\n\\n                if (av_get_channel_layout_nb_channels(codec->channel_layout) != codec->channels)\\n\\n                    codec->channel_layout = 0;\\n\\n                ost->audio_resample = codec->sample_rate != icodec->sample_rate || audio_sync_method > 1;\\n\\n                icodec->request_channels = codec->channels;\\n\\n                ist->decoding_needed = 1;\\n\\n                ost->encoding_needed = 1;\\n\\n                ost->resample_sample_fmt  = icodec->sample_fmt;\\n\\n                ost->resample_sample_rate = icodec->sample_rate;\\n\\n                ost->resample_channels    = icodec->channels;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_VIDEO:\\n\\n                if (codec->pix_fmt == PIX_FMT_NONE)\\n\\n                    codec->pix_fmt = icodec->pix_fmt;\\n\\n                choose_pixel_fmt(ost->st, ost->enc);\\n\\n\\n\\n                if (ost->st->codec->pix_fmt == PIX_FMT_NONE) {\\n\\n                    fprintf(stderr, \"Video pixel format is unknown, stream cannot be encoded\\\\n\");\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n                ost->video_resample = codec->width   != icodec->width  ||\\n\\n                                      codec->height  != icodec->height ||\\n\\n                                      codec->pix_fmt != icodec->pix_fmt;\\n\\n                if (ost->video_resample) {\\n\\n                    codec->bits_per_raw_sample= frame_bits_per_raw_sample;\\n\\n                }\\n\\n                if (!codec->width || !codec->height) {\\n\\n                    codec->width  = icodec->width;\\n\\n                    codec->height = icodec->height;\\n\\n                }\\n\\n                ost->resample_height = icodec->height;\\n\\n                ost->resample_width  = icodec->width;\\n\\n                ost->resample_pix_fmt= icodec->pix_fmt;\\n\\n                ost->encoding_needed = 1;\\n\\n                ist->decoding_needed = 1;\\n\\n\\n\\n                if (!ost->frame_rate.num)\\n\\n                    ost->frame_rate = ist->st->r_frame_rate.num ? ist->st->r_frame_rate : (AVRational){25,1};\\n\\n                if (ost->enc && ost->enc->supported_framerates && !force_fps) {\\n\\n                    int idx = av_find_nearest_q_idx(ost->frame_rate, ost->enc->supported_framerates);\\n\\n                    ost->frame_rate = ost->enc->supported_framerates[idx];\\n\\n                }\\n\\n                codec->time_base = (AVRational){ost->frame_rate.den, ost->frame_rate.num};\\n\\n                if(   av_q2d(codec->time_base) < 0.001 && video_sync_method\\n\\n                   && (video_sync_method==1 || (video_sync_method<0 && !(os->oformat->flags & AVFMT_VARIABLE_FPS)))){\\n\\n                    av_log(os, AV_LOG_WARNING, \"Frame rate very high for a muxer not effciciently supporting it.\\\\n\"\\n\\n                                               \"Please consider specifiying a lower framerate, a different muxer or -vsync 2\\\\n\");\\n\\n                }\\n\\n\\n\\n#if CONFIG_AVFILTER\\n\\n                if (configure_video_filters(ist, ost)) {\\n\\n                    fprintf(stderr, \"Error opening filters!\\\\n\");\\n\\n                    exit(1);\\n\\n                }\\n\\n#endif\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_SUBTITLE:\\n\\n                ost->encoding_needed = 1;\\n\\n                ist->decoding_needed = 1;\\n\\n                break;\\n\\n            default:\\n\\n                abort();\\n\\n                break;\\n\\n            }\\n\\n            /* two pass mode */\\n\\n            if (ost->encoding_needed && codec->codec_id != CODEC_ID_H264 &&\\n\\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\\n\\n                char logfilename[1024];\\n\\n                FILE *f;\\n\\n\\n\\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\",\\n\\n                         pass_logfilename_prefix ? pass_logfilename_prefix : DEFAULT_PASS_LOGFILENAME_PREFIX,\\n\\n                         i);\\n\\n                if (codec->flags & CODEC_FLAG_PASS1) {\\n\\n                    f = fopen(logfilename, \"wb\");\\n\\n                    if (!f) {\\n\\n                        fprintf(stderr, \"Cannot write log file \\'%s\\' for pass-1 encoding: %s\\\\n\", logfilename, strerror(errno));\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                    ost->logfile = f;\\n\\n                } else {\\n\\n                    char  *logbuffer;\\n\\n                    size_t logbuffer_size;\\n\\n                    if (read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\\n\\n                        fprintf(stderr, \"Error reading log file \\'%s\\' for pass-2 encoding\\\\n\", logfilename);\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                    codec->stats_in = logbuffer;\\n\\n                }\\n\\n            }\\n\\n        }\\n\\n        if(codec->codec_type == AVMEDIA_TYPE_VIDEO){\\n\\n            /* maximum video buffer size is 6-bytes per pixel, plus DPX header size */\\n\\n            int size= codec->width * codec->height;\\n\\n            bit_buffer_size= FFMAX(bit_buffer_size, 6*size + 1664);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    if (!bit_buffer)\\n\\n        bit_buffer = av_malloc(bit_buffer_size);\\n\\n    if (!bit_buffer) {\\n\\n        fprintf(stderr, \"Cannot allocate %d bytes output buffer\\\\n\",\\n\\n                bit_buffer_size);\\n\\n        ret = AVERROR(ENOMEM);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    /* open each encoder */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        if (ost->encoding_needed) {\\n\\n            AVCodec *codec = ost->enc;\\n\\n            AVCodecContext *dec = input_streams[ost->source_index].st->codec;\\n\\n            if (!codec) {\\n\\n                snprintf(error, sizeof(error), \"Encoder (codec id %d) not found for output stream #%d.%d\",\\n\\n                         ost->st->codec->codec_id, ost->file_index, ost->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            if (dec->subtitle_header) {\\n\\n                ost->st->codec->subtitle_header = av_malloc(dec->subtitle_header_size);\\n\\n                if (!ost->st->codec->subtitle_header) {\\n\\n                    ret = AVERROR(ENOMEM);\\n\\n                    goto dump_format;\\n\\n                }\\n\\n                memcpy(ost->st->codec->subtitle_header, dec->subtitle_header, dec->subtitle_header_size);\\n\\n                ost->st->codec->subtitle_header_size = dec->subtitle_header_size;\\n\\n            }\\n\\n            if (avcodec_open2(ost->st->codec, codec, &ost->opts) < 0) {\\n\\n                snprintf(error, sizeof(error), \"Error while opening encoder for output stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\",\\n\\n                        ost->file_index, ost->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            assert_codec_experimental(ost->st->codec, 1);\\n\\n            assert_avoptions(ost->opts);\\n\\n            if (ost->st->codec->bit_rate && ost->st->codec->bit_rate < 1000)\\n\\n                av_log(NULL, AV_LOG_WARNING, \"The bitrate parameter is set too low.\"\\n\\n                                             \"It takes bits/s as argument, not kbits/s\\\\n\");\\n\\n            extra_size += ost->st->codec->extradata_size;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* open each decoder */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            AVCodec *codec = ist->dec;\\n\\n            if (!codec)\\n\\n                codec = avcodec_find_decoder(ist->st->codec->codec_id);\\n\\n            if (!codec) {\\n\\n                snprintf(error, sizeof(error), \"Decoder (codec id %d) not found for input stream #%d.%d\",\\n\\n                        ist->st->codec->codec_id, ist->file_index, ist->st->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            if (avcodec_open2(ist->st->codec, codec, &ist->opts) < 0) {\\n\\n                snprintf(error, sizeof(error), \"Error while opening decoder for input stream #%d.%d\",\\n\\n                        ist->file_index, ist->st->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            assert_codec_experimental(ist->st->codec, 0);\\n\\n            assert_avoptions(ost->opts);\\n\\n            //if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\\n\\n            //    ist->st->codec->flags |= CODEC_FLAG_REPEAT_FIELD;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* init pts */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        AVStream *st;\\n\\n        ist = &input_streams[i];\\n\\n        st= ist->st;\\n\\n        ist->pts = st->avg_frame_rate.num ? - st->codec->has_b_frames*AV_TIME_BASE / av_q2d(st->avg_frame_rate) : 0;\\n\\n        ist->next_pts = AV_NOPTS_VALUE;\\n\\n        ist->is_start = 1;\\n\\n    }\\n\\n\\n\\n    /* set meta data information from input file if required */\\n\\n    for (i=0;i<nb_meta_data_maps;i++) {\\n\\n        AVFormatContext *files[2];\\n\\n        AVDictionary    **meta[2];\\n\\n        int j;\\n\\n\\n\\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\\\\n\\n        if ((index) < 0 || (index) >= (nb_elems)) {\\\\\\n\\n            snprintf(error, sizeof(error), \"Invalid %s index %d while processing metadata maps\\\\n\",\\\\\\n\\n                     (desc), (index));\\\\\\n\\n            ret = AVERROR(EINVAL);\\\\\\n\\n            goto dump_format;\\\\\\n\\n        }\\n\\n\\n\\n        int out_file_index = meta_data_maps[i][0].file;\\n\\n        int in_file_index = meta_data_maps[i][1].file;\\n\\n        if (in_file_index < 0 || out_file_index < 0)\\n\\n            continue;\\n\\n        METADATA_CHECK_INDEX(out_file_index, nb_output_files, \"output file\")\\n\\n        METADATA_CHECK_INDEX(in_file_index, nb_input_files, \"input file\")\\n\\n\\n\\n        files[0] = output_files[out_file_index];\\n\\n        files[1] = input_files[in_file_index].ctx;\\n\\n\\n\\n        for (j = 0; j < 2; j++) {\\n\\n            MetadataMap *map = &meta_data_maps[i][j];\\n\\n\\n\\n            switch (map->type) {\\n\\n            case \\'g\\':\\n\\n                meta[j] = &files[j]->metadata;\\n\\n                break;\\n\\n            case \\'s\\':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_streams, \"stream\")\\n\\n                meta[j] = &files[j]->streams[map->index]->metadata;\\n\\n                break;\\n\\n            case \\'c\\':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_chapters, \"chapter\")\\n\\n                meta[j] = &files[j]->chapters[map->index]->metadata;\\n\\n                break;\\n\\n            case \\'p\\':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_programs, \"program\")\\n\\n                meta[j] = &files[j]->programs[map->index]->metadata;\\n\\n                break;\\n\\n            }\\n\\n        }\\n\\n\\n\\n        av_dict_copy(meta[0], *meta[1], AV_DICT_DONT_OVERWRITE);\\n\\n    }\\n\\n\\n\\n    /* copy global metadata by default */\\n\\n    if (metadata_global_autocopy) {\\n\\n\\n\\n        for (i = 0; i < nb_output_files; i++)\\n\\n            av_dict_copy(&output_files[i]->metadata, input_files[0].ctx->metadata,\\n\\n                         AV_DICT_DONT_OVERWRITE);\\n\\n    }\\n\\n\\n\\n    /* copy chapters according to chapter maps */\\n\\n    for (i = 0; i < nb_chapter_maps; i++) {\\n\\n        int infile  = chapter_maps[i].in_file;\\n\\n        int outfile = chapter_maps[i].out_file;\\n\\n\\n\\n        if (infile < 0 || outfile < 0)\\n\\n            continue;\\n\\n        if (infile >= nb_input_files) {\\n\\n            snprintf(error, sizeof(error), \"Invalid input file index %d in chapter mapping.\\\\n\", infile);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        if (outfile >= nb_output_files) {\\n\\n            snprintf(error, sizeof(error), \"Invalid output file index %d in chapter mapping.\\\\n\",outfile);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        copy_chapters(infile, outfile);\\n\\n    }\\n\\n\\n\\n    /* copy chapters from the first input file that has them*/\\n\\n    if (!nb_chapter_maps)\\n\\n        for (i = 0; i < nb_input_files; i++) {\\n\\n            if (!input_files[i].ctx->nb_chapters)\\n\\n                continue;\\n\\n\\n\\n            for (j = 0; j < nb_output_files; j++)\\n\\n                if ((ret = copy_chapters(i, j)) < 0)\\n\\n                    goto dump_format;\\n\\n            break;\\n\\n        }\\n\\n\\n\\n    /* open files and write file headers */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        if (avformat_write_header(os, &output_opts[i]) < 0) {\\n\\n            snprintf(error, sizeof(error), \"Could not write header for output file #%d (incorrect codec parameters ?)\", i);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        assert_avoptions(output_opts[i]);\\n\\n        if (strcmp(output_files[i]->oformat->name, \"rtp\")) {\\n\\n            want_sdp = 0;\\n\\n        }\\n\\n    }\\n\\n\\n\\n dump_format:\\n\\n    /* dump the file output parameters - cannot be done before in case\\n\\n       of stream copy */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n    }\\n\\n\\n\\n    /* dump the stream mapping */\\n\\n    if (verbose >= 0) {\\n\\n        fprintf(stderr, \"Stream mapping:\\\\n\");\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            ost = ost_table[i];\\n\\n            fprintf(stderr, \"  Stream #%d.%d -> #%d.%d\",\\n\\n                    input_streams[ost->source_index].file_index,\\n\\n                    input_streams[ost->source_index].st->index,\\n\\n                    ost->file_index,\\n\\n                    ost->index);\\n\\n            if (ost->sync_ist != &input_streams[ost->source_index])\\n\\n                fprintf(stderr, \" [sync #%d.%d]\",\\n\\n                        ost->sync_ist->file_index,\\n\\n                        ost->sync_ist->st->index);\\n\\n            fprintf(stderr, \"\\\\n\");\\n\\n        }\\n\\n    }\\n\\n\\n\\n    if (ret) {\\n\\n        fprintf(stderr, \"%s\\\\n\", error);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    if (want_sdp) {\\n\\n        print_sdp(output_files, nb_output_files);\\n\\n    }\\n\\n\\n\\n    if (!using_stdin) {\\n\\n        if(verbose >= 0)\\n\\n            fprintf(stderr, \"Press [q] to stop, [?] for help\\\\n\");\\n\\n        avio_set_interrupt_cb(decode_interrupt_cb);\\n\\n    }\\n\\n    term_init();\\n\\n\\n\\n    timer_start = av_gettime();\\n\\n\\n\\n    for(; received_sigterm == 0;) {\\n\\n        int file_index, ist_index;\\n\\n        AVPacket pkt;\\n\\n        double ipts_min;\\n\\n        double opts_min;\\n\\n\\n\\n    redo:\\n\\n        ipts_min= 1e100;\\n\\n        opts_min= 1e100;\\n\\n        /* if \\'q\\' pressed, exits */\\n\\n        if (!using_stdin) {\\n\\n            if (q_pressed)\\n\\n                break;\\n\\n            /* read_key() returns 0 on EOF */\\n\\n            key = read_key();\\n\\n            if (key == \\'q\\')\\n\\n                break;\\n\\n            if (key == \\'+\\') verbose++;\\n\\n            if (key == \\'-\\') verbose--;\\n\\n            if (key == \\'s\\') qp_hist     ^= 1;\\n\\n            if (key == \\'h\\'){\\n\\n                if (do_hex_dump){\\n\\n                    do_hex_dump = do_pkt_dump = 0;\\n\\n                } else if(do_pkt_dump){\\n\\n                    do_hex_dump = 1;\\n\\n                } else\\n\\n                    do_pkt_dump = 1;\\n\\n                av_log_set_level(AV_LOG_DEBUG);\\n\\n            }\\n\\n            if (key == \\'d\\' || key == \\'D\\'){\\n\\n                int debug=0;\\n\\n                if(key == \\'D\\') {\\n\\n                    debug = input_streams[0].st->codec->debug<<1;\\n\\n                    if(!debug) debug = 1;\\n\\n                    while(debug & (FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) //unsupported, would just crash\\n\\n                        debug += debug;\\n\\n                }else\\n\\n                    scanf(\"%d\", &debug);\\n\\n                for(i=0;i<nb_input_streams;i++) {\\n\\n                    input_streams[i].st->codec->debug = debug;\\n\\n                }\\n\\n                for(i=0;i<nb_ostreams;i++) {\\n\\n                    ost = ost_table[i];\\n\\n                    ost->st->codec->debug = debug;\\n\\n                }\\n\\n                if(debug) av_log_set_level(AV_LOG_DEBUG);\\n\\n                fprintf(stderr,\"debug=%d\\\\n\", debug);\\n\\n            }\\n\\n            if (key == \\'?\\'){\\n\\n                fprintf(stderr, \"key    function\\\\n\"\\n\\n                                \"?      show this help\\\\n\"\\n\\n                                \"+      increase verbosity\\\\n\"\\n\\n                                \"-      decrease verbosity\\\\n\"\\n\\n                                \"D      cycle through available debug modes\\\\n\"\\n\\n                                \"h      dump packets/hex press to cycle through the 3 states\\\\n\"\\n\\n                                \"q      quit\\\\n\"\\n\\n                                \"s      Show QP histogram\\\\n\"\\n\\n                );\\n\\n            }\\n\\n        }\\n\\n\\n\\n        /* select the stream that we must read now by looking at the\\n\\n           smallest output pts */\\n\\n        file_index = -1;\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            double ipts, opts;\\n\\n            ost = ost_table[i];\\n\\n            os = output_files[ost->file_index];\\n\\n            ist = &input_streams[ost->source_index];\\n\\n            if(ist->is_past_recording_time || no_packet[ist->file_index])\\n\\n                continue;\\n\\n                opts = ost->st->pts.val * av_q2d(ost->st->time_base);\\n\\n            ipts = (double)ist->pts;\\n\\n            if (!input_files[ist->file_index].eof_reached){\\n\\n                if(ipts < ipts_min) {\\n\\n                    ipts_min = ipts;\\n\\n                    if(input_sync ) file_index = ist->file_index;\\n\\n                }\\n\\n                if(opts < opts_min) {\\n\\n                    opts_min = opts;\\n\\n                    if(!input_sync) file_index = ist->file_index;\\n\\n                }\\n\\n            }\\n\\n            if(ost->frame_number >= max_frames[ost->st->codec->codec_type]){\\n\\n                file_index= -1;\\n\\n                break;\\n\\n            }\\n\\n        }\\n\\n        /* if none, if is finished */\\n\\n        if (file_index < 0) {\\n\\n            if(no_packet_count){\\n\\n                no_packet_count=0;\\n\\n                memset(no_packet, 0, sizeof(no_packet));\\n\\n                usleep(10000);\\n\\n                continue;\\n\\n            }\\n\\n            break;\\n\\n        }\\n\\n\\n\\n        /* finish if limit size exhausted */\\n\\n        if (limit_filesize != 0 && limit_filesize <= avio_tell(output_files[0]->pb))\\n\\n            break;\\n\\n\\n\\n        /* read a frame from it and output it in the fifo */\\n\\n        is = input_files[file_index].ctx;\\n\\n        ret= av_read_frame(is, &pkt);\\n\\n        if(ret == AVERROR(EAGAIN)){\\n\\n            no_packet[file_index]=1;\\n\\n            no_packet_count++;\\n\\n            continue;\\n\\n        }\\n\\n        if (ret < 0) {\\n\\n            input_files[file_index].eof_reached = 1;\\n\\n            if (opt_shortest)\\n\\n                break;\\n\\n            else\\n\\n                continue;\\n\\n        }\\n\\n\\n\\n        no_packet_count=0;\\n\\n        memset(no_packet, 0, sizeof(no_packet));\\n\\n\\n\\n        if (do_pkt_dump) {\\n\\n            av_pkt_dump_log2(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump,\\n\\n                             is->streams[pkt.stream_index]);\\n\\n        }\\n\\n        /* the following test is needed in case new streams appear\\n\\n           dynamically in stream : we ignore them */\\n\\n        if (pkt.stream_index >= input_files[file_index].ctx->nb_streams)\\n\\n            goto discard_packet;\\n\\n        ist_index = input_files[file_index].ist_index + pkt.stream_index;\\n\\n        ist = &input_streams[ist_index];\\n\\n        if (ist->discard)\\n\\n            goto discard_packet;\\n\\n\\n\\n        if (pkt.dts != AV_NOPTS_VALUE)\\n\\n            pkt.dts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n        if (pkt.pts != AV_NOPTS_VALUE)\\n\\n            pkt.pts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n\\n\\n        if (ist->ts_scale) {\\n\\n            if(pkt.pts != AV_NOPTS_VALUE)\\n\\n                pkt.pts *= ist->ts_scale;\\n\\n            if(pkt.dts != AV_NOPTS_VALUE)\\n\\n                pkt.dts *= ist->ts_scale;\\n\\n        }\\n\\n\\n\\n//        fprintf(stderr, \"next:%\"PRId64\" dts:%\"PRId64\" off:%\"PRId64\" %d\\\\n\", ist->next_pts, pkt.dts, input_files[ist->file_index].ts_offset, ist->st->codec->codec_type);\\n\\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_pts != AV_NOPTS_VALUE\\n\\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\\n\\n            int64_t pkt_dts= av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\\n\\n            int64_t delta= pkt_dts - ist->next_pts;\\n\\n            if((FFABS(delta) > 1LL*dts_delta_threshold*AV_TIME_BASE || pkt_dts+1<ist->pts)&& !copy_ts){\\n\\n                input_files[ist->file_index].ts_offset -= delta;\\n\\n                if (verbose > 2)\\n\\n                    fprintf(stderr, \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\\\n\",\\n\\n                            delta, input_files[ist->file_index].ts_offset);\\n\\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n                if(pkt.pts != AV_NOPTS_VALUE)\\n\\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n            }\\n\\n        }\\n\\n\\n\\n        /* finish if recording time exhausted */\\n\\n        if (recording_time != INT64_MAX &&\\n\\n            (pkt.pts != AV_NOPTS_VALUE ?\\n\\n                av_compare_ts(pkt.pts, ist->st->time_base, recording_time + start_time, (AVRational){1, 1000000})\\n\\n                    :\\n\\n                av_compare_ts(ist->pts, AV_TIME_BASE_Q, recording_time + start_time, (AVRational){1, 1000000})\\n\\n            )>= 0) {\\n\\n            ist->is_past_recording_time = 1;\\n\\n            goto discard_packet;\\n\\n        }\\n\\n\\n\\n        //fprintf(stderr,\"read #%d.%d size=%d\\\\n\", ist->file_index, ist->st->index, pkt.size);\\n\\n        if (output_packet(ist, ist_index, ost_table, nb_ostreams, &pkt) < 0) {\\n\\n\\n\\n            if (verbose >= 0)\\n\\n                fprintf(stderr, \"Error while decoding stream #%d.%d\\\\n\",\\n\\n                        ist->file_index, ist->st->index);\\n\\n            if (exit_on_error)\\n\\n                ffmpeg_exit(1);\\n\\n            av_free_packet(&pkt);\\n\\n            goto redo;\\n\\n        }\\n\\n\\n\\n    discard_packet:\\n\\n        av_free_packet(&pkt);\\n\\n\\n\\n        /* dump report by using the output first video and audio streams */\\n\\n        print_report(output_files, ost_table, nb_ostreams, 0);\\n\\n    }\\n\\n\\n\\n    /* at the end of stream, we must flush the decoder buffers */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            output_packet(ist, i, ost_table, nb_ostreams, NULL);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    term_exit();\\n\\n\\n\\n    /* write the trailer if needed and close file */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        av_write_trailer(os);\\n\\n    }\\n\\n\\n\\n    /* dump report by using the first video and audio streams */\\n\\n    print_report(output_files, ost_table, nb_ostreams, 1);\\n\\n\\n\\n    /* close each encoder */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        if (ost->encoding_needed) {\\n\\n            av_freep(&ost->st->codec->stats_in);\\n\\n            avcodec_close(ost->st->codec);\\n\\n        }\\n\\n#if CONFIG_AVFILTER\\n\\n        avfilter_graph_free(&ost->graph);\\n\\n#endif\\n\\n    }\\n\\n\\n\\n    /* close each decoder */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            avcodec_close(ist->st->codec);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* finished ! */\\n\\n    ret = 0;\\n\\n\\n\\n fail:\\n\\n    av_freep(&bit_buffer);\\n\\n\\n\\n    if (ost_table) {\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            ost = ost_table[i];\\n\\n            if (ost) {\\n\\n                if (ost->st->stream_copy)\\n\\n                    av_freep(&ost->st->codec->extradata);\\n\\n                if (ost->logfile) {\\n\\n                    fclose(ost->logfile);\\n\\n                    ost->logfile = NULL;\\n\\n                }\\n\\n                av_fifo_free(ost->fifo); /* works even if fifo is not\\n\\n                                             initialized but set to zero */\\n\\n                av_freep(&ost->st->codec->subtitle_header);\\n\\n                av_free(ost->resample_frame.data[0]);\\n\\n                av_free(ost->forced_kf_pts);\\n\\n                if (ost->video_resample)\\n\\n                    sws_freeContext(ost->img_resample_ctx);\\n\\n                if (ost->resample)\\n\\n                    audio_resample_close(ost->resample);\\n\\n                if (ost->reformat_ctx)\\n\\n                    av_audio_convert_free(ost->reformat_ctx);\\n\\n                av_dict_free(&ost->opts);\\n\\n                av_free(ost);\\n\\n            }\\n\\n        }\\n\\n        av_free(ost_table);\\n\\n    }\\n\\n    return ret;\\n\\n}\\n', 'idx': 1}\n",
      "\n",
      "\n",
      "Example 3:\n",
      "{'project': 'FFmpeg', 'commit_id': '5d5de3eba4c7890c2e8077f5b4ae569671d11cf8', 'target': 0, 'func': 'static void v4l2_free_buffer(void *opaque, uint8_t *unused)\\n\\n{\\n\\n    V4L2Buffer* avbuf = opaque;\\n\\n    V4L2m2mContext *s = buf_to_m2mctx(avbuf);\\n\\n\\n\\n    if (atomic_fetch_sub(&avbuf->context_refcount, 1) == 1) {\\n\\n        atomic_fetch_sub_explicit(&s->refcount, 1, memory_order_acq_rel);\\n\\n\\n\\n        if (s->reinit) {\\n\\n            if (!atomic_load(&s->refcount))\\n\\n                sem_post(&s->refsync);\\n\\n        } else if (avbuf->context->streamon)\\n\\n            ff_v4l2_buffer_enqueue(avbuf);\\n\\n\\n\\n        av_buffer_unref(&avbuf->context_ref);\\n\\n    }\\n\\n}\\n', 'idx': 2}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):  # Print first 3 examples\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(train_data[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5cc485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: Counter({0: 11836, 1: 10018})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count classes in the training set\n",
    "class_counts = Counter([entry['target'] for entry in train_data])\n",
    "print(f\"Class distribution in training set: {class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f5fa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot class distribution\n",
    "labels = ['Secure (0)', 'Vulnerable (1)']\n",
    "counts = [class_counts[0], class_counts[1]]\n",
    "\n",
    "plt.bar(labels, counts)\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3d8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21854 training samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the full dataset\n",
    "with open(\"function.json\", \"r\") as f:\n",
    "    full_dataset = json.load(f)\n",
    "\n",
    "# Load the train indices\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    train_indices = [int(line.strip()) for line in f]\n",
    "\n",
    "# Extract training samples\n",
    "train_data = [full_dataset[i] for i in train_indices]\n",
    "print(f\"Extracted {len(train_data)} training samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ecc846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 21854 training samples.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Function to tokenize the dataset\n",
    "def tokenize_dataset(data, tokenizer, max_length=512):\n",
    "    tokenized_data = []\n",
    "    for entry in data:\n",
    "        tokens = tokenizer(\n",
    "            entry['func'],  # Tokenize the \"func\" field\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_data.append({\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),  # Remove batch dimension\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": entry['target']  # Use the \"target\" field as the label\n",
    "        })\n",
    "    return tokenized_data\n",
    "\n",
    "# Tokenize the training data\n",
    "tokenized_train = tokenize_dataset(train_data, tokenizer)\n",
    "print(f\"Tokenized {len(tokenized_train)} training samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4237989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized training data saved to 'tokenized_train.pt'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save the tokenized data\n",
    "torch.save(tokenized_train, \"tokenized_train.pt\")\n",
    "print(\"Tokenized training data saved to 'tokenized_train.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ffe0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized validation data saved to 'tokenized_valid.pt'.\n",
      "Tokenized test data saved to 'tokenized_test.pt'.\n"
     ]
    }
   ],
   "source": [
    "# Extract validation samples\n",
    "with open(\"valid.txt\", \"r\") as f:\n",
    "    valid_indices = [int(line.strip()) for line in f]\n",
    "valid_data = [full_dataset[i] for i in valid_indices]\n",
    "\n",
    "# Tokenize validation data\n",
    "tokenized_valid = tokenize_dataset(valid_data, tokenizer)\n",
    "\n",
    "# Save tokenized validation data\n",
    "torch.save(tokenized_valid, \"tokenized_valid.pt\")\n",
    "print(\"Tokenized validation data saved to 'tokenized_valid.pt'.\")\n",
    "\n",
    "# Extract test samples\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    test_indices = [int(line.strip()) for line in f]\n",
    "test_data = [full_dataset[i] for i in test_indices]\n",
    "\n",
    "# Tokenize test data\n",
    "tokenized_test = tokenize_dataset(test_data, tokenizer)\n",
    "\n",
    "# Save tokenized test data\n",
    "torch.save(tokenized_test, \"tokenized_test.pt\")\n",
    "print(\"Tokenized test data saved to 'tokenized_test.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1b3f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21854 tokenized training samples.\n",
      "{'input_ids': tensor([    0, 47908,  1009,   571,  1215, 33869,  1215,   119, 48429,   288,\n",
      "         1640, 10799,  1215,    90,   295,  1215, 46823,    43, 50118, 50118,\n",
      "        45152, 50140,  1437,  1437,  1437, 27148, 20401,  1571,  1215, 33407,\n",
      "         1215,    29,  4291, 30529,  1640,   282,  1215, 46823,  4397, 50140,\n",
      "         1437,  1437,  1437,   671,   486,  1975,  1640,   134,     6,   295,\n",
      "         1215, 46823, 45994,   321, 17487,   112,  4832,   295,  1215, 46823,\n",
      "         4397, 50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenized data\n",
    "tokenized_train = torch.load(\"tokenized_train.pt\")\n",
    "print(f\"Loaded {len(tokenized_train)} tokenized training samples.\")\n",
    "\n",
    "# Inspect the first sample\n",
    "print(tokenized_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c05eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/7b/92/e3f810d0910a71979fe7341803e187cbf85e2b50146c8aa3796eb7bc51b4/accelerate-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from accelerate) (2.1.2)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.0 from https://files.pythonhosted.org/packages/44/5a/dc6af87c61f89b23439eb95521e4e99862636cfd538ae12fd36be5483e5f/huggingface_hub-0.26.5-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/08/8c/ece3bf8756506a890bd980eca02f47f9d98dfbf5ce16eda1368f53560f67/safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m381.5/381.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, accelerate\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.2\n",
      "    Uninstalling safetensors-0.3.2:\n",
      "      Successfully uninstalled safetensors-0.3.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed accelerate-1.2.0 huggingface-hub-0.26.5 safetensors-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce64f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b197a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b626f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urllib3 version: 2.2.3\n",
      "botocore version: 1.35.36\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import botocore\n",
    "\n",
    "print(f\"urllib3 version: {urllib3.__version__}\")\n",
    "print(f\"botocore version: {botocore.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c19fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1535610713.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Ensure this file exists\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1535610713.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(\"tokenized_valid.pt\")  # Ensure this file exists\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 22:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuned and saved!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the Tokenized Datasets\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Ensure this file exists\n",
    "valid_data = torch.load(\"tokenized_valid.pt\")  # Ensure this file exists\n",
    "\n",
    "# Step 2: Define a Dataset Class\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(self.data[idx][\"label\"]),\n",
    "        }\n",
    "\n",
    "# Convert to Dataset format\n",
    "train_dataset = TokenizedDataset(train_data[:1000])  # Use a subset for light fine-tuning\n",
    "valid_dataset = TokenizedDataset(valid_data[:200])\n",
    "\n",
    "# Step 3: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
    "\n",
    "# Step 4: Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./light_finetuned_codebert\",  # Directory to save model\n",
    "    evaluation_strategy=\"epoch\",             # Evaluate at the end of each epoch\n",
    "    save_strategy=\"no\",                      # Do not save intermediate checkpoints\n",
    "    num_train_epochs=1,                      # Light fine-tuning\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",                    # Directory for logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,            # No need to load the best model\n",
    ")\n",
    "\n",
    "# Step 5: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")\n",
    "\n",
    "# Step 6: Fine-Tune the Model\n",
    "trainer.train()\n",
    "\n",
    "# Step 7: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./light_finetuned_codebert\")\n",
    "tokenizer.save_pretrained(\"./light_finetuned_codebert\")\n",
    "\n",
    "print(\"Model fine-tuned and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd4237c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 invalid labels:\n",
      "  Sample 0: Invalid label '1'\n",
      "  Sample 1: Invalid label '0'\n",
      "  Sample 2: Invalid label '1'\n",
      "  Sample 3: Invalid label '0'\n",
      "  Sample 4: Invalid label '0'\n",
      "  Sample 5: Invalid label '0'\n",
      "  Sample 6: Invalid label '0'\n",
      "  Sample 7: Invalid label '1'\n",
      "  Sample 8: Invalid label '1'\n",
      "  Sample 9: Invalid label '0'\n",
      "Please fix the invalid labels.\n"
     ]
    }
   ],
   "source": [
    "def validate_labels(dataset):\n",
    "    \"\"\"\n",
    "    Validate that all labels in the dataset are correctly formatted.\n",
    "    \"\"\"\n",
    "    invalid_labels = []\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        label = sample[\"labels\"]\n",
    "        if not isinstance(label, int) or label not in [0, 1]:\n",
    "            invalid_labels.append((idx, label))\n",
    "\n",
    "    if len(invalid_labels) == 0:\n",
    "        print(\"All labels are correctly formatted (integers, 0 or 1).\")\n",
    "    else:\n",
    "        print(f\"Found {len(invalid_labels)} invalid labels:\")\n",
    "        for idx, label in invalid_labels[:10]:  # Display up to 10 invalid labels\n",
    "            print(f\"  Sample {idx}: Invalid label '{label}'\")\n",
    "        print(\"Please fix the invalid labels.\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming `train_dataset` is your tokenized dataset\n",
    "validate_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9377dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_labels(dataset):\n",
    "    \"\"\"\n",
    "    Convert tensor or string labels in the dataset to Python integers.\n",
    "    \"\"\"\n",
    "    for sample in dataset:\n",
    "        label = sample[\"labels\"]\n",
    "        # Convert tensor to int if necessary\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            sample[\"labels\"] = int(label.item())\n",
    "        # Convert string to int if necessary\n",
    "        elif isinstance(label, str):\n",
    "            sample[\"labels\"] = int(label)\n",
    "    print(\"All labels have been converted to integers.\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec74c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels have been converted to integers.\n",
      "All labels have been converted to integers.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = fix_labels(train_dataset)\n",
    "valid_dataset = fix_labels(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ab0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels are correctly formatted (integers, 0 or 1).\n"
     ]
    }
   ],
   "source": [
    "validate_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6a713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    return {\n",
    "        \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "        \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "        \"labels\": int(self.data[idx][\"label\"]),  # Convert labels to integers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "411cdc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664bf061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([    0, 47908,  1009,   571,  1215, 33869,  1215,   119, 48429,   288,\n",
      "         1640, 10799,  1215,    90,   295,  1215, 46823,    43, 50118, 50118,\n",
      "        45152, 50140,  1437,  1437,  1437, 27148, 20401,  1571,  1215, 33407,\n",
      "         1215,    29,  4291, 30529,  1640,   282,  1215, 46823,  4397, 50140,\n",
      "         1437,  1437,  1437,   671,   486,  1975,  1640,   134,     6,   295,\n",
      "         1215, 46823, 45994,   321, 17487,   112,  4832,   295,  1215, 46823,\n",
      "         4397, 50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: tensor(1)\n",
      "Input IDs: tensor([    0, 42653, 13842,  8462,  1215,  6460,  1215, 37379,    90,  1640,\n",
      "        46674,  1009, 46134,     6, 10035,  7852,  1009,   705,     6, 10759,\n",
      "        16224,  1009, 13650,     6, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 13842,\n",
      "         1009,  1517, 35485,     6, 37943, 13540, 14385,   642,    43, 50118,\n",
      "        50118, 45152, 50140,  1437,  1437,  1437,   579,   510,   591,   500,\n",
      "        10644, 49605,  1009,   417, 22393,  5457,  6178,   591,   500,  1215,\n",
      "        10644,  1215, 15299, 42849,  3411,  1640, 46134,  4397, 50140,  1437,\n",
      "         1437,  1437, 37943,  1009, 14385,  5457, 48955,   131, 50140,  1437,\n",
      "         1437,  1437,  6979,   856, 38585,  1215, 48025,  1215, 25616,     6,\n",
      "          856, 38585,  1215, 48025,     6,   856, 38585,  1215, 11583,   131,\n",
      "        50140,  1437,  1437,  1437, 13842,  1009, 37379,    90,   131, 50140,\n",
      "        50140,  1437,  1437,  1437,   114, 48209,   417, 22393, 46613, 37379,\n",
      "           90,    43, 25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,   825,  1215, 12528,  1215, 15755,  1640,   705,     6, 48955,\n",
      "            6, 22379,   642,  4397, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,   671,   131, 50140,  1437,  1437,  1437, 35524, 50140,\n",
      "        50140,  1437,  1437,  1437,   856, 38585,  5457, 12402,   438, 46613,\n",
      "        37379,    90,   131, 50140,  1437,  1437,  1437,   856, 38585,  1215,\n",
      "        48025,  5457, 12402,   438, 46613, 37379,    90,  1215, 13124,  1215,\n",
      "        48025,   131, 50140,  1437,  1437,  1437,   856, 38585,  1215, 11583,\n",
      "         5457,   321,   131, 50140, 50140,  1437,  1437,  1437,   109, 25522,\n",
      "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437, 10759, 16224,\n",
      "         1009, 13650,  5457, 48955,   131, 50140,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437, 10759, 29916,   856, 38585,  1215, 41723,  1009,\n",
      "        27128,  5457, 48955,   131, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  6979,  8462,  1215,  8476,  5457,   321,     6,   766,\n",
      "         1215,  8476,  5457,   321,   131, 50140,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437, 49315,  2881,  1215,    90,  6694,   131, 50140,\n",
      "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  6694,  5457,\n",
      "          856, 38585,  1215, 25616,  1215, 10058,  1640, 37379,    90,     6,\n",
      "          856, 38585,  1215, 48025,     6,   359, 37379,    90,  1215, 48025,\n",
      "         1215, 25616,  4397, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  5405,    36, 10058,    43, 25522, 50140,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,   403,   274, 23858,  1215,   387, 39764,\n",
      "         1215,   487, 38023,    35, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,   856, 38585,  1215, 11583,\n",
      "        49789, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,   766,  5457,   856, 38585,  1215,  6460,  1215,\n",
      "        13650,  1640, 37379,    90,     6,   856, 38585,  1215, 48025,     6,\n",
      "          359, 13650,  1215,  8476,  4397, 50140,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,   825,  1215, 13124,\n",
      "         1215, 25384,  1640,   705,     6,   766,     6, 48955,     6,   321,\n",
      "            6,   359, 14385,  4397, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,   114,    36, 14385,    43,\n",
      "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  5849,  1215, 27128,\n",
      "        32814,  1640, 14385,   642,     6, 22379,  4397, 50140,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,   671,   131, 50140,  1437,  1437,  1437,  1437,\n",
      "         1437,     2])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Label: tensor(0)\n",
      "Input IDs: tensor([    0, 42653, 13842,  1296,  1215,  3662,   330,  1215, 12745,  1640,\n",
      "        38866, 19085,  1397,  1009,  3662,   330,     6,   251,  6184,     6,\n",
      "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  6979,  4027,  1215,    90,\n",
      "         6184,  1215, 48025,     6,  6979,  4027,  1215,    90,  6184,  1215,\n",
      "        11432,     6, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  6979,  4027,\n",
      "         1215,    90,  6147,     6,  6979,  4027,  1215,    90,  3212,     6,\n",
      "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437, 49460,  1057,  1215, 38323,\n",
      "           43, 50118, 50118, 45152, 50140,  1437,  1437,  1437, 13842,  1009,\n",
      "        43106,  1215, 48939,  5457, 48955,   131, 50140,  1437,  1437,  1437,\n",
      "         1209,  5330, 18157, 13565, 26997,  2231, 32822,   131, 50140,  1437,\n",
      "         1437,  1437, 13842,  1009, 48427,  1215, 48939,  5457, 48955,   131,\n",
      "        50140,  1437,  1437,  1437,  6979, 48781,  1215,  4903,  5457,  8127,\n",
      "         1215,   495, 16646,   131, 50140, 50140,  1437,  1437,  1437,   114,\n",
      "           36, 43106,    43, 25522, 50140,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,   740,  6195,  1215, 48939,  5457,   821,  1215,   119,\n",
      "        48429,  1640, 43106,  1215, 11432,  4397, 50140,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437, 26012,  8738,  1640, 48427,  1215, 48939,\n",
      "            6,  6184,     6,  6184,  1215, 11432,  4397, 50140,  1437,  1437,\n",
      "         1437, 35524, 50140, 50140,  1437,  1437,  1437,  6184,  1215, 48939,\n",
      "         5457,   821,  1215,   119, 48429,  1640, 11432,  4397, 50140,  1437,\n",
      "         1437,  1437,   114,    36, 43106,    43, 25522, 50140,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437, 26012,  8738,  1640, 43106,  1215,\n",
      "        48939,     6,  6184,     6,  3212,  4397, 50140,  1437,  1437,  1437,\n",
      "        35524,  1493, 25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437, 26012,  8738,  1640, 43106,  1215, 48939,     6,   321,  1178,\n",
      "          612,     6,  3212,  4397, 50140,  1437,  1437,  1437, 35524, 50140,\n",
      "        50140,  1437,  1437,  1437,  2231,   991,   257,  1215,   118,  7067,\n",
      "          438,  1215, 25153, 49763,  1343, 32822,     6,   112,  4397, 50140,\n",
      "         1437,  1437,  1437,  2231,   991,   257,  1215,   118,  7067,   438,\n",
      "         1215,  4917, 49763,  1343, 32822,     6,  6184,  1215, 48939,     6,\n",
      "         3212,  4397, 50140, 50140,  1437,  1437,  1437,  3089,   330,  1215,\n",
      "          102,  1020,  1215, 47561,   705,  1640,  3662,   330,     6,  6147,\n",
      "            6,   359,  1343, 32822,     6,   321,     6,  3089,   330,  1215,\n",
      "        43926,  1215, 27057,     6,   359,   281, 46707,  1215,  4903,  4397,\n",
      "        50140,  1437,  1437,  1437,   150,    36,   281, 46707,  1215,  4903,\n",
      "        45994,  8127,  1215,   495, 16646,    43, 25522, 50140,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1049,  1215, 31290,  1215, 37405,\n",
      "         1640, 22303,  4397, 50140,  1437,  1437,  1437, 35524, 50140, 50140,\n",
      "         1437,  1437,  1437,   114,    36,  3463, 13771,  1215, 38323,    43,\n",
      "        25522, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   821,\n",
      "         1215, 46346,  1640,   281, 46707,  1215,  4903, 49333,   321,  4397,\n",
      "        50140,  1437,  1437,  1437, 35524,  1493, 25522, 50140,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,   821,  1215, 46346,  1640,   281,\n",
      "        46707,  1215,  4903, 45994,   321,  4397, 50140,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,   114,    36, 43106,    43, 25522, 50140,\n",
      "         1437,     2])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Label: tensor(1)\n",
      "Input IDs: tensor([    0, 42653, 13842,   385, 16142,  1215, 29631,  1640, 47908,  1009,\n",
      "         1517, 35485,     6,  1002,  1215, 39409,  1215, 49439,  1215,    90,\n",
      "        49649,     6, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437, 49315,  4027,  1215,    90,\n",
      "         7398,     6, 39023,  1836,    43, 50118, 50118, 45152, 50140,  1437,\n",
      "         1437,  1437, 48565,  6783,    42,     4,  1437,    85,    18,    70,\n",
      "         1330,     7, 10994,  2620,  5801,     8, 11808,     4,  1437, 48404,\n",
      "        50118, 50118, 24303, 50118,     2,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: tensor(0)\n",
      "Input IDs: tensor([    0, 42653, 38252, 36757,  1009,  4651,  1215, 46234,  1215,  8656,\n",
      "         1640, 47261, 48522,  1009,   139,     6, 17307, 48587, 48522,  1009,\n",
      "         1975,     6, 49562, 17307, 18801, 40118,  1907,     6,  6979,  1300,\n",
      "         1215, 18480,    43, 50118, 50118, 45152, 50140,  1437,  1437,  1437,\n",
      "        38252, 36757,  1009,  2603,   131, 50140,  1437,  1437,  1437, 17307,\n",
      "        36757,  1009,   620,  5457,  6402, 34609,  1215,  4651,  1215,  8656,\n",
      "         1640,  1975,     6, 48955,  4397, 50140,  1437,  1437,  1437,  6979,\n",
      "        13561,  1178,  1437,  1437,  1437,  1437,  1437,  5457,  1021,   438,\n",
      "        46613, 40460,  1215,  8656,    29,   111,   112,     6,  5494,  5457,\n",
      "          321,   131, 50140,  1437,  1437,  1437, 10759, 16224,  1009,  4311,\n",
      "        17884,  5457, 48955,     6,  1009,   958,  1215, 11070,  5457, 48955,\n",
      "          131, 50140,  1437,  1437,  1437, 16224,  1009, 25616,     6,  1009,\n",
      "        29659,  3204,  1215, 10058,  5457, 48955,   131, 50140,  1437,  1437,\n",
      "         1437,  1457,  2231,  8056,  5457,   111,   134,   131, 50140,  1437,\n",
      "         1437,  1437,  6979,   939,   131, 50140, 50140,  1437,  1437,  1437,\n",
      "          114, 48209,   620,    43, 25522, 50140,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  6402,  1215, 12376,  1640, 49728,     6, 17307,\n",
      "         1215, 45403,  1215,   597,  2571,  2118,     6,    22, 35299,    45,\n",
      "        42793,  4615,     4, 37457,   282, 45751, 50140,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437,  4205,  1215, 28644,  1640,   134,  4397,\n",
      "        50140,  1437,  1437,  1437, 35524, 50140, 50140,  1437,  1437,  1437,\n",
      "          114,    36,  1975, 46613, 40460,  1215,  8656,    29,   111,   112,\n",
      "        28696,  1021, 46613, 40460,  1215,  8656,   808,  1215, 32557,    43,\n",
      "        50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1690, 46613,\n",
      "          808,  5457,  1021, 46613,  8656,   808,  1215, 32557, 10975,  1975,\n",
      "        46613, 40460,  1215,  8656,    29,   111,   112, 44082, 50140, 50140,\n",
      "         1437,  1437,  1437,  8837,  4581,  1215,  2747, 37327,  1640, 46234,\n",
      "         1215,  8656,    29,     6,   295,   428,  1215, 46234,  1215,  8656,\n",
      "           29,  4397, 50140,  1437,  1437,  1437,   114, 48209,  1640,  2603,\n",
      "         5457,  6402,  1215,   119, 48429,   329,  1640, 10799,  1116, 49570,\n",
      "         2603, 49639, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         4205,  1215, 28644,  1640,   134,  4397, 50140,  1437,  1437,  1437,\n",
      "         4195,  1215,  8656,    29, 10975, 40460,  1215, 46234,  1215,  8656,\n",
      "           29,   111,   112,   742,  5457, 29122,   131, 50140, 50140,  1437,\n",
      "         1437,  1437, 29122, 46613, 21710,  1215, 18480,  5457,   295,   428,\n",
      "         1215, 46234,  1215, 42018,   111,   112,   131, 50140,  1437,  1437,\n",
      "         1437, 29122, 46613, 18480,  1437,  1437,  1437,  1437,  1437,  5457,\n",
      "        13561,  1178,   131, 50140,  1437,  1437,  1437, 29122, 46613,   620,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  5457,  1690,\n",
      "          131, 50140,  1437,  1437,  1437,  1690, 46613, 29659,  3204,  5489,\n",
      "        46613, 29659,  3204,  1215, 12528,  5457,  1907,   131, 50140, 50140,\n",
      "         1437,  1437,  1437,  5494,  5457,  2807,  1215, 14210, 15362,  1640,\n",
      "          139,     6,  1021,   438,     6, 29122,  4397, 50140,  1437,  1437,\n",
      "         1437,   114,    36,  4903, 28696,   321,    43, 25522, 50140,  1437,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  6402,  1215, 12376,  1640,\n",
      "        49728,     6, 17307,  1215, 45403,  1215,   597,  2571,  2118,     6,\n",
      "           22, 30192, 18099,    41,  9689, 15362,    13,  4615,    22, 50140,\n",
      "         1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         1437,  1437,  1437,  1437, 49608,   417,    35,   207,   417, 37457,\n",
      "          282,  1297, 29122, 46613, 21710,  1215, 18480,     6, 29122, 46613,\n",
      "        18480,  4397, 50140,  1437,  1437,  1437,  1437,  1437,  1437,  1437,\n",
      "         4205,     2])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Label: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Input IDs:\", train_dataset[i][\"input_ids\"])\n",
    "    print(\"Attention Mask:\", train_dataset[i][\"attention_mask\"])\n",
    "    print(\"Label:\", train_dataset[i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f470a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1540600122.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Ensure this file exists\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1540600122.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(\"tokenized_valid.pt\")  # Ensure this file exists\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Step 5: Define Training Arguments for Full Fine-Tuning\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     39\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./improved_finetuned_codebert\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     43\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     44\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m     46\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     47\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     49\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Disable mixed precision\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Use Metal Performance Shaders\u001b[39;00m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Step 6: Define Metrics to Track Class Performance\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(pred):\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Step 1: Load the Tokenized Datasets\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Ensure this file exists\n",
    "valid_data = torch.load(\"tokenized_valid.pt\")  # Ensure this file exists\n",
    "\n",
    "# Step 2: Define a Dataset Class\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "            \"labels\": int(self.data[idx][\"label\"]),  # Ensure labels are integers\n",
    "        }\n",
    "\n",
    "# Use full datasets for training and validation\n",
    "train_dataset = TokenizedDataset(train_data)\n",
    "valid_dataset = TokenizedDataset(valid_data)\n",
    "\n",
    "# Step 3: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Step 4: Set Up Dynamic Padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Step 5: Define Training Arguments for Full Fine-Tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./improved_finetuned_codebert\",  # Directory to save model\n",
    "    evaluation_strategy=\"epoch\",               # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                     # Save model after each epoch\n",
    "    save_total_limit=2,                        # Limit saved checkpoints\n",
    "    num_train_epochs=2,                        # Train for 3 epochs\n",
    "    per_device_train_batch_size=16,            # Batch size per device\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,                        # Learning rate for fine updates\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",                      # Directory for logs\n",
    "    logging_steps=50,\n",
    "    no_cuda=True,                              # Use CPU\n",
    "    fp16=False,                                # Disable mixed precision\n",
    ")\n",
    "\n",
    "# Step 6: Define Metrics to Track Class Performance\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Step 7: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Step 8: Fine-Tune the Model\n",
    "trainer.train()\n",
    "\n",
    "# Step 9: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "tokenizer.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "\n",
    "print(\"Model fine-tuned and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50ba10c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1432259879.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1432259879.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0)  # Add batch dimension\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1432259879.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0)  # Add batch dimension\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.06%\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Secure (0)       0.54      1.00      0.70      1477\n",
      "Vulnerable (1)       0.00      0.00      0.00      1255\n",
      "\n",
      "      accuracy                           0.54      2732\n",
      "     macro avg       0.27      0.50      0.35      2732\n",
      "  weighted avg       0.29      0.54      0.38      2732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the Tokenizer and Model\n",
    "model_dir = \"./light_finetuned_codebert\"  # Directory where the fine-tuned model is saved\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Step 2: Load the Test Dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "\n",
    "# Define the Dataset Class for the Test Set\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "            \"labels\": int(self.data[idx][\"label\"]),  # Ensure labels are integers\n",
    "        }\n",
    "\n",
    "test_dataset = TokenizedDataset(test_data)\n",
    "\n",
    "# Step 3: Make Predictions on the Test Set\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for sample in test_dataset:\n",
    "        input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0)  # Add batch dimension\n",
    "        attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0)  # Add batch dimension\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        pred = torch.argmax(logits, dim=-1).item()\n",
    "        predictions.append(pred)\n",
    "        labels.append(sample[\"labels\"])\n",
    "\n",
    "# Step 4: Calculate Metrics\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Detailed Classification Report\n",
    "report = classification_report(labels, predictions, target_names=[\"Secure (0)\", \"Vulnerable (1)\"])\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c520c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Label Distribution: Counter({0: 11836, 1: 10018})\n",
      "Validation Set Label Distribution: Counter({0: 1545, 1: 1187})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_labels = [sample['label'] for sample in train_data]\n",
    "valid_labels = [sample['label'] for sample in valid_data]\n",
    "\n",
    "print(\"Training Set Label Distribution:\", Counter(train_labels))\n",
    "print(\"Validation Set Label Distribution:\", Counter(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2ff2d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/6a/97/1780e3dd8733da30ff1051b8cbd8006e4824b76028558a58c31e790c09cd/torchaudio-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchaudio-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torchaudio-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217202c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # Should return True if MPS is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01b583f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1273934276.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1273934276.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(\"tokenized_valid.pt\")\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of  Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 83\u001b[0m\n\u001b[1;32m     73\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     74\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     75\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Step 8: Fine-Tune the Model\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Step 9: Save the Fine-Tuned Model\u001b[39;00m\n\u001b[1;32m     86\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./improved_finetuned_codebert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2165\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2166\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2167\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2168\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2169\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3655\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3655\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3661\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3709\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3707\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3708\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3709\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1318\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1318\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[1;32m   1319\u001b[0m     input_ids,\n\u001b[1;32m   1320\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1321\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1322\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1323\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1324\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1325\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1326\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1327\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1328\u001b[0m )\n\u001b[1;32m   1329\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1330\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    977\u001b[0m     embedding_output,\n\u001b[1;32m    978\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    979\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    980\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    981\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    982\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    983\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    984\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    985\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    986\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    987\u001b[0m )\n\u001b[1;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    622\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         output_attentions,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    632\u001b[0m         hidden_states,\n\u001b[1;32m    633\u001b[0m         attention_mask,\n\u001b[1;32m    634\u001b[0m         layer_head_mask,\n\u001b[1;32m    635\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    636\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    637\u001b[0m         past_key_value,\n\u001b[1;32m    638\u001b[0m         output_attentions,\n\u001b[1;32m    639\u001b[0m     )\n\u001b[1;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    521\u001b[0m         hidden_states,\n\u001b[1;32m    522\u001b[0m         attention_mask,\n\u001b[1;32m    523\u001b[0m         head_mask,\n\u001b[1;32m    524\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    525\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:456\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    448\u001b[0m         hidden_states,\n\u001b[1;32m    449\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m         output_attentions,\n\u001b[1;32m    455\u001b[0m     )\n\u001b[0;32m--> 456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:398\u001b[0m, in \u001b[0;36mRobertaSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    397\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 398\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    399\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Step 1: Load the Tokenized Datasets\n",
    "train_data = torch.load(\"tokenized_train.pt\")\n",
    "valid_data = torch.load(\"tokenized_valid.pt\")\n",
    "\n",
    "# Step 2: Define a Dataset Class\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "            \"labels\": int(self.data[idx][\"label\"]),\n",
    "        }\n",
    "\n",
    "# Use full datasets for training and validation\n",
    "train_dataset = TokenizedDataset(train_data)\n",
    "valid_dataset = TokenizedDataset(valid_data)\n",
    "\n",
    "# Step 3: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Set model device to MPS\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 4: Set Up Dynamic Padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Step 5: Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./improved_finetuned_codebert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    no_cuda=True,       # Ensure no CUDA is used; MPS or CPU only\n",
    "    fp16=False,         # Explicitly disable mixed precision\n",
    ")\n",
    "\n",
    "# Step 6: Define Metrics to Track Class Performance\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Step 7: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Step 8: Fine-Tune the Model\n",
    "trainer.train()\n",
    "\n",
    "# Step 9: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "tokenizer.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "\n",
    "print(\"Model fine-tuned and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f232c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/4186812653.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/4186812653.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load(\"tokenized_valid.pt\")\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of  Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2732' max='2732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2732/2732 4:45:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.600400</td>\n",
       "      <td>0.585404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning resumed and completed. Model saved!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the Tokenized Datasets\n",
    "train_data = torch.load(\"tokenized_train.pt\")\n",
    "valid_data = torch.load(\"tokenized_valid.pt\")\n",
    "\n",
    "# Step 2: Define Dataset Class\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.data[idx][\"attention_mask\"],\n",
    "            \"labels\": int(self.data[idx][\"label\"]),\n",
    "        }\n",
    "\n",
    "# Convert to Dataset format\n",
    "train_dataset = TokenizedDataset(train_data)\n",
    "valid_dataset = TokenizedDataset(valid_data)\n",
    "\n",
    "# Step 3: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Step 4: Set Up Dynamic Padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Step 5: Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./improved_finetuned_codebert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True,  # Forces CPU usage\n",
    "    fp16=False,    # Disable mixed precision\n",
    ")\n",
    "\n",
    "# Step 6: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Step 7: Resume Fine-Tuning from Checkpoint\n",
    "last_checkpoint = \"./improved_finetuned_codebert/checkpoint-1366\"\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "\n",
    "# Step 8: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "tokenizer.save_pretrained(\"./improved_finetuned_codebert\")\n",
    "\n",
    "print(\"Fine-tuning resumed and completed. Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0506e658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 04:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/3475693547.py:9: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library  Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38769fd85d7a4a43b4fa49aefbd5aa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.5854037404060364, 'eval_model_preparation_time': 0.0012, 'eval_accuracy': 0.6489751098096632, 'eval_precision': 0.6881188118811881, 'eval_recall': 0.35130581297388375, 'eval_f1': 0.4651422197434467, 'eval_runtime': 270.15, 'eval_samples_per_second': 10.113, 'eval_steps_per_second': 0.318}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "\n",
    "# Assuming `valid_dataset` is your validation dataset\n",
    "# and `data_collator` is already defined.\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    acc = metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Re-initialize Trainer for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2026e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1248137464.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1248137464.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"input_ids\": torch.tensor(self.data[idx][\"input_ids\"]),\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/1248137464.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"attention_mask\": torch.tensor(self.data[idx][\"attention_mask\"]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with confidence scores saved to 'test_predictions_with_confidence.csv'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "checkpoint_path = \"./improved_finetuned_codebert/checkpoint-2732\"  # Path to the final checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Force PyTorch to use the MPS backend if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your test dataset\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.data[idx][\"input_ids\"]),\n",
    "            \"attention_mask\": torch.tensor(self.data[idx][\"attention_mask\"]),\n",
    "        }\n",
    "\n",
    "# Load your test dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "test_dataset = TokenizedDataset(test_data)\n",
    "\n",
    "# Custom function for predictions with confidence scores\n",
    "def predict_with_confidence(model, tokenizer, dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "    results = []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        predicted_labels = probabilities.argmax(axis=-1)\n",
    "        confidence_scores = probabilities.max(axis=-1)\n",
    "        \n",
    "        for idx in range(len(predicted_labels)):\n",
    "            results.append({\n",
    "                \"input_text\": tokenizer.decode(input_ids[idx], skip_special_tokens=True),\n",
    "                \"predicted_label\": int(predicted_labels[idx]),\n",
    "                \"confidence_score\": float(confidence_scores[idx]),\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run predictions\n",
    "predictions = predict_with_confidence(model, tokenizer, test_dataset)\n",
    "\n",
    "# Save results to a CSV\n",
    "df_results = pd.DataFrame(predictions)\n",
    "df_results.to_csv(\"test_predictions_with_confidence.csv\", index=False)\n",
    "\n",
    "print(\"Predictions with confidence scores saved to 'test_predictions_with_confidence.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e33e8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/556942126.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between confidence and correctness: 0.2779\n",
      "Spearman Correlation between confidence and correctness: 0.2543\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions Confidence Summary:\n",
      "count    1734.000000\n",
      "mean        0.709102\n",
      "std         0.165874\n",
      "min         0.500049\n",
      "25%         0.563756\n",
      "50%         0.656569\n",
      "75%         0.868148\n",
      "max         0.997959\n",
      "Name: confidence_score, dtype: float64\n",
      "\n",
      "Incorrect Predictions Confidence Summary:\n",
      "count    998.000000\n",
      "mean       0.620259\n",
      "std        0.109946\n",
      "min        0.500263\n",
      "25%        0.538501\n",
      "50%        0.586088\n",
      "75%        0.670231\n",
      "max        0.996710\n",
      "Name: confidence_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the predictions dataset\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "\n",
    "# Step 2: Load the original test dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels from the dataset\n",
    "\n",
    "# Step 3: Add true labels to the DataFrame\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 4: Add Correctness Column\n",
    "df[\"is_correct\"] = df[\"predicted_label\"] == df[\"true_label\"]\n",
    "\n",
    "# Step 5: Separate Confidence Scores\n",
    "correct_confidences = df[df[\"is_correct\"]][\"confidence_score\"]\n",
    "incorrect_confidences = df[~df[\"is_correct\"]][\"confidence_score\"]\n",
    "\n",
    "# Step 6: Compute Correlation\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "correlation, _ = pearsonr(df[\"is_correct\"], df[\"confidence_score\"])\n",
    "spearman_corr, _ = spearmanr(df[\"is_correct\"], df[\"confidence_score\"])\n",
    "\n",
    "print(f\"Pearson Correlation between confidence and correctness: {correlation:.4f}\")\n",
    "print(f\"Spearman Correlation between confidence and correctness: {spearman_corr:.4f}\")\n",
    "\n",
    "# Step 7: Visualize Confidence Distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(correct_confidences, bins=30, alpha=0.5, label=\"Correct Predictions\", color=\"green\")\n",
    "plt.hist(incorrect_confidences, bins=30, alpha=0.5, label=\"Incorrect Predictions\", color=\"red\")\n",
    "plt.xlabel(\"Confidence Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.title(\"Confidence Score Distribution: Correct vs Incorrect Predictions\")\n",
    "plt.show()\n",
    "\n",
    "# Step 8: Save the updated dataset (optional)\n",
    "df.to_csv(\"test_predictions_with_true_labels.csv\", index=False)\n",
    "\n",
    "# Step 9: Summary Statistics\n",
    "print(\"Correct Predictions Confidence Summary:\")\n",
    "print(correct_confidences.describe())\n",
    "\n",
    "print(\"\\nIncorrect Predictions Confidence Summary:\")\n",
    "print(incorrect_confidences.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1965542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy calculation completed. Updated dataset saved as 'test_predictions_with_entropy.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "\n",
    "# Step 2: Ensure the dataset contains the necessary columns\n",
    "if \"confidence_score\" not in df.columns:\n",
    "    raise ValueError(\"The dataset must include a 'confidence_score' column representing the probability of the predicted class.\")\n",
    "\n",
    "# Step 3: Calculate prediction entropy\n",
    "def calculate_entropy(row):\n",
    "    p = row[\"confidence_score\"]  # Confidence for the predicted class\n",
    "    p = np.clip(p, 1e-12, 1.0)   # Avoid log(0)\n",
    "    q = 1 - p                    # Confidence for the other class\n",
    "    entropy = -p * np.log2(p) - q * np.log2(q)\n",
    "    return entropy\n",
    "\n",
    "# Add entropy column\n",
    "df[\"prediction_entropy\"] = df.apply(calculate_entropy, axis=1)\n",
    "\n",
    "# Step 4: Save the updated dataset\n",
    "df.to_csv(\"test_predictions_with_entropy.csv\", index=False)\n",
    "\n",
    "print(\"Entropy calculation completed. Updated dataset saved as 'test_predictions_with_entropy.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15cc4f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/691980491.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Confidence Scores:\n",
      "count    1734.000000\n",
      "mean        0.709102\n",
      "std         0.165874\n",
      "min         0.500049\n",
      "25%         0.563756\n",
      "50%         0.656569\n",
      "75%         0.868148\n",
      "max         0.997959\n",
      "Name: confidence_score, dtype: float64\n",
      "\n",
      "Incorrect Confidence Scores:\n",
      "count    998.000000\n",
      "mean       0.620259\n",
      "std        0.109946\n",
      "min        0.500263\n",
      "25%        0.538501\n",
      "50%        0.586088\n",
      "75%        0.670231\n",
      "max        0.996710\n",
      "Name: confidence_score, dtype: float64\n",
      "\n",
      "Pearson Correlation between entropy and correctness: -0.2811\n",
      "Spearman Correlation between entropy and correctness: -0.2543\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "file_path = \"test_predictions_with_confidence.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Load the original test dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels from the dataset\n",
    "\n",
    "# Step 3: Add true labels to the DataFrame\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 4: Add Correctness Column\n",
    "df[\"is_correct\"] = df[\"predicted_label\"] == df[\"true_label\"]\n",
    "\n",
    "# Step 5: Separate Confidence Scores\n",
    "correct_confidences = df[df[\"is_correct\"]][\"confidence_score\"]\n",
    "incorrect_confidences = df[~df[\"is_correct\"]][\"confidence_score\"]\n",
    "\n",
    "# Step 6: Calculate prediction entropy\n",
    "def calculate_entropy(confidence_score):\n",
    "    prob_1 = confidence_score\n",
    "    prob_0 = 1 - confidence_score\n",
    "    probabilities = np.array([prob_0, prob_1])\n",
    "    probabilities = np.clip(probabilities, 1e-12, 1.0)  # Avoid log(0)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "df[\"prediction_entropy\"] = df[\"confidence_score\"].apply(calculate_entropy)\n",
    "\n",
    "# Step 7: Save the updated dataset\n",
    "output_file = \"test_predictions_with_entropy.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Step 8: Correlation with correctness\n",
    "correlation_pearson = df[\"prediction_entropy\"].corr(df[\"is_correct\"].astype(int))\n",
    "correlation_spearman = df[\"prediction_entropy\"].corr(df[\"is_correct\"].astype(int), method=\"spearman\")\n",
    "\n",
    "# Display results\n",
    "print(\"Correct Confidence Scores:\")\n",
    "print(correct_confidences.describe())\n",
    "print(\"\\nIncorrect Confidence Scores:\")\n",
    "print(incorrect_confidences.describe())\n",
    "print(f\"\\nPearson Correlation between entropy and correctness: {correlation_pearson:.4f}\")\n",
    "print(f\"Spearman Correlation between entropy and correctness: {correlation_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1227f639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>true_label</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>prediction_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558397</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.774915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663211</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.921713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951676</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.279236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526273</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.974156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584445</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779009</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.761973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.613718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  predicted_label  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                1   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...                0   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                0   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                1   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                0   \n",
       "...                                                 ...              ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                1   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                0   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                0   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                0   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                0   \n",
       "\n",
       "      confidence_score  true_label  is_correct  prediction_entropy  \n",
       "0             0.558397           1        True            0.990138  \n",
       "1             0.771769           1       False            0.774915  \n",
       "2             0.663211           1       False            0.921713  \n",
       "3             0.951676           1        True            0.279236  \n",
       "4             0.526273           1       False            0.998007  \n",
       "...                ...         ...         ...                 ...  \n",
       "2727          0.594357           1        True            0.974156  \n",
       "2728          0.925011           1       False            0.384273  \n",
       "2729          0.584445           1       False            0.979326  \n",
       "2730          0.779009           0        True            0.761973  \n",
       "2731          0.848445           1       False            0.613718  \n",
       "\n",
       "[2732 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80e34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./improved_finetuned_codebert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/3461717735.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_5494/3461717735.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training latent representations...\n",
      "Extracting test latent representations...\n",
      "Calculating LSA...\n",
      "Calculating DSA...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Step 1: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"  # Replace with your fine-tuned model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "# Ensure \"test_predictions_with_confidence.csv\" and \"tokenized_train.pt\" exist\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n",
    "\n",
    "# Decode texts from tokenized datasets\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in train_data]\n",
    "\n",
    "# Step 3: Extract Latent Representations\n",
    "def extract_latent_representations(texts, layer=-2, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extract latent representations from the model.\n",
    "    :param texts: List of text inputs\n",
    "    :param layer: Layer index to extract representations from\n",
    "    :param batch_size: Batch size for efficient processing\n",
    "    :return: Array of latent representations\n",
    "    \"\"\"\n",
    "    latent_representations = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[layer]  # Shape: (batch_size, seq_length, hidden_size)\n",
    "            batch_representations = hidden_states.mean(dim=1)  # Mean pooling over seq_length\n",
    "            latent_representations.append(batch_representations.cpu().numpy())\n",
    "    return np.vstack(latent_representations)\n",
    "\n",
    "print(\"Extracting training latent representations...\")\n",
    "train_representations = extract_latent_representations(train_texts)\n",
    "\n",
    "print(\"Extracting test latent representations...\")\n",
    "test_representations = extract_latent_representations(test_texts)\n",
    "\n",
    "# Step 4: Calculate LSA\n",
    "print(\"Calculating LSA...\")\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.5).fit(train_representations)\n",
    "lsa_scores = -kde.score_samples(test_representations)  # Negative log likelihoods\n",
    "\n",
    "# Step 5: Calculate DSA\n",
    "print(\"Calculating DSA...\")\n",
    "distances = np.linalg.norm(test_representations[:, np.newaxis] - train_representations, axis=2)\n",
    "nearest_distances = np.min(distances, axis=1)  # Min distance to any training sample\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dsa_scores = scaler.fit_transform(nearest_distances.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Add LSA and DSA to the Dataset\n",
    "df[\"lsa_score\"] = lsa_scores\n",
    "df[\"dsa_score\"] = dsa_scores\n",
    "\n",
    "# Step 7: Save the Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_lsa_dsa.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_lsa_dsa.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f40640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/12414876.py:8: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./improved_finetuned_codebert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/12414876.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/12414876.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training latent representations for LSA...\n",
      "Extracting test latent representations for LSA...\n",
      "Calculating LSA...\n",
      "Updated dataset saved as 'test_predictions_with_lsa.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Use MPS if available, otherwise fall back to CPU\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "\n",
    "# Step 1: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"  # Replace with your fine-tuned model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n",
    "\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in train_data]\n",
    "\n",
    "# Step 3: Extract Latent Representations\n",
    "def extract_latent_representations(texts, layer=-2, batch_size=32):\n",
    "    latent_representations = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[layer]\n",
    "            batch_representations = hidden_states.mean(dim=1)\n",
    "            latent_representations.append(batch_representations.cpu().numpy())\n",
    "    return np.vstack(latent_representations)\n",
    "\n",
    "print(\"Extracting training latent representations for LSA...\")\n",
    "train_representations = extract_latent_representations(train_texts)\n",
    "\n",
    "print(\"Extracting test latent representations for LSA...\")\n",
    "test_representations = extract_latent_representations(test_texts)\n",
    "\n",
    "# Step 4: Calculate LSA\n",
    "print(\"Calculating LSA...\")\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.5).fit(train_representations)\n",
    "lsa_scores = -kde.score_samples(test_representations)\n",
    "\n",
    "# Step 5: Add LSA to the Dataset\n",
    "df[\"lsa_score\"] = lsa_scores\n",
    "\n",
    "# Step 6: Save the Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_lsa.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_lsa.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30541e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>lsa_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558397</td>\n",
       "      <td>210.784513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>211.064370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663211</td>\n",
       "      <td>183.168739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951676</td>\n",
       "      <td>187.846960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526273</td>\n",
       "      <td>182.651668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>182.647076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>208.740274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584445</td>\n",
       "      <td>259.075386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779009</td>\n",
       "      <td>198.493403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>201.913769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  predicted_label  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                1   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...                0   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                0   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                1   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                0   \n",
       "...                                                 ...              ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                1   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                0   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                0   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                0   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                0   \n",
       "\n",
       "      confidence_score   lsa_score  \n",
       "0             0.558397  210.784513  \n",
       "1             0.771769  211.064370  \n",
       "2             0.663211  183.168739  \n",
       "3             0.951676  187.846960  \n",
       "4             0.526273  182.651668  \n",
       "...                ...         ...  \n",
       "2727          0.594357  182.647076  \n",
       "2728          0.925011  208.740274  \n",
       "2729          0.584445  259.075386  \n",
       "2730          0.779009  198.493403  \n",
       "2731          0.848445  201.913769  \n",
       "\n",
       "[2732 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between LSA score and system failure: -0.0089 (p-value: 6.4343e-01)\n",
      "Spearman Correlation between LSA score and system failure: -0.0055 (p-value: 7.7524e-01)\n",
      "Updated dataset saved as 'test_predictions_with_lsa_and_failure.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/3412111873.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Step 1: Load the Dataset with LSA and True Labels\n",
    "df = pd.read_csv(\"test_predictions_with_lsa.csv\")  # File from the LSA calculation step\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "\n",
    "# Step 2: Extract True Labels\n",
    "true_labels = [entry[\"label\"] for entry in test_data]\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 3: Add Failure Column\n",
    "df[\"is_failure\"] = df[\"predicted_label\"] != df[\"true_label\"]\n",
    "\n",
    "# Step 4: Calculate Correlation\n",
    "lsa_scores = df[\"lsa_score\"]\n",
    "failure_indicators = df[\"is_failure\"].astype(int)  # Convert boolean to integer for correlation\n",
    "\n",
    "# Pearson Correlation\n",
    "pearson_corr, pearson_p_value = pearsonr(lsa_scores, failure_indicators)\n",
    "\n",
    "# Spearman Correlation\n",
    "spearman_corr, spearman_p_value = spearmanr(lsa_scores, failure_indicators)\n",
    "\n",
    "# Step 5: Print Results\n",
    "print(f\"Pearson Correlation between LSA score and system failure: {pearson_corr:.4f} (p-value: {pearson_p_value:.4e})\")\n",
    "print(f\"Spearman Correlation between LSA score and system failure: {spearman_corr:.4f} (p-value: {spearman_p_value:.4e})\")\n",
    "\n",
    "# Optional: Save Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_lsa_and_failure.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_lsa_and_failure.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b81b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/567163393.py:8: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./improved_finetuned_codebert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/567163393.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_68638/567163393.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training latent representations for DSA...\n",
      "Extracting test latent representations for DSA...\n",
      "Calculating DSA...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Use MPS if available, otherwise fall back to CPU\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "\n",
    "# Step 1: Load Pre-trained Model and Tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"  # Replace with your fine-tuned model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "df = pd.read_csv(\"test_predictions_with_lsa.csv\")  # Use the file from the LSA step\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n",
    "\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in train_data]\n",
    "\n",
    "# Step 3: Extract Latent Representations\n",
    "def extract_latent_representations(texts, layer=-2, batch_size=32):\n",
    "    latent_representations = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[layer]\n",
    "            batch_representations = hidden_states.mean(dim=1)\n",
    "            latent_representations.append(batch_representations.cpu().numpy())\n",
    "    return np.vstack(latent_representations)\n",
    "\n",
    "print(\"Extracting training latent representations for DSA...\")\n",
    "train_representations = extract_latent_representations(train_texts)\n",
    "\n",
    "print(\"Extracting test latent representations for DSA...\")\n",
    "test_representations = extract_latent_representations(test_texts)\n",
    "\n",
    "# Step 4: Calculate DSA\n",
    "print(\"Calculating DSA...\")\n",
    "distances = np.linalg.norm(test_representations[:, np.newaxis] - train_representations, axis=2)\n",
    "nearest_distances = np.min(distances, axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dsa_scores = scaler.fit_transform(nearest_distances.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 5: Add DSA to the Dataset\n",
    "df[\"dsa_score\"] = dsa_scores\n",
    "\n",
    "# Step 6: Save the Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_lsa_dsa.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_lsa_dsa.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb1fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./improved_finetuned_codebert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_75317/946595418.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test latent representations...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"  # Replace with your model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Load your test dataset (adjust based on your setup)\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "\n",
    "# Decode texts from tokenized test dataset\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "\n",
    "# Extract Latent Representations Function\n",
    "def extract_latent_representations(texts, layer=-2, batch_size=32):\n",
    "    latent_representations = []\n",
    "    model.eval()\n",
    "    model.to(\"mps\")  # Use \"mps\" for Mac M2 GPU\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"mps\")\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[layer]  # Extract the layer representation\n",
    "            batch_representations = hidden_states.mean(dim=1)  # Mean pooling over sequence length\n",
    "            latent_representations.append(batch_representations.cpu().numpy())\n",
    "    return np.vstack(latent_representations)\n",
    "\n",
    "# Extract test latent representations\n",
    "print(\"Extracting test latent representations...\")\n",
    "test_representations = extract_latent_representations(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a132096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training latent representations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_75317/1042456602.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in torch.load(\"tokenized_train.pt\")]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating DSA scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating DSA in batches: 100%|| 28/28 [06:57<00:00, 14.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load training representations\n",
    "print(\"Extracting training latent representations...\")\n",
    "train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in torch.load(\"tokenized_train.pt\")]\n",
    "train_representations = extract_latent_representations(train_texts)\n",
    "\n",
    "# Function to calculate DSA scores in batches\n",
    "def calculate_dsa_in_batches(test_representations, train_representations, batch_size=100):\n",
    "    dsa_scores = []\n",
    "    for i in tqdm(range(0, len(test_representations), batch_size), desc=\"Calculating DSA in batches\"):\n",
    "        # Select a batch of test representations\n",
    "        test_batch = test_representations[i:i + batch_size]\n",
    "\n",
    "        # Compute distances between test batch and all training samples\n",
    "        distances = np.linalg.norm(test_batch[:, np.newaxis] - train_representations, axis=2)\n",
    "        \n",
    "        # Find the minimum distance (nearest neighbor) for each test sample in the batch\n",
    "        nearest_distances = np.min(distances, axis=1)\n",
    "        dsa_scores.extend(nearest_distances)\n",
    "    \n",
    "    return np.array(dsa_scores)\n",
    "\n",
    "# Calculate DSA scores\n",
    "print(\"Calculating DSA scores...\")\n",
    "raw_dsa_scores = calculate_dsa_in_batches(test_representations, train_representations)\n",
    "\n",
    "# Normalize DSA scores to range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "dsa_scores = scaler.fit_transform(raw_dsa_scores.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bbce4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSA scores added and dataset saved as 'test_predictions_with_dsa.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load your existing dataset with predictions\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "\n",
    "# Add DSA scores to the dataset\n",
    "df[\"dsa_score\"] = dsa_scores\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"test_predictions_with_dsa.csv\", index=False)\n",
    "print(\"DSA scores added and dataset saved as 'test_predictions_with_dsa.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8e16a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between DSA score and system failure: 0.0154 (p-value: 4.2030e-01)\n",
      "Spearman Correlation between DSA score and system failure: 0.0020 (p-value: 9.1620e-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_75317/1887554940.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Step 1: Load the dataset with DSA scores and the test dataset\n",
    "df = pd.read_csv(\"test_predictions_with_dsa.csv\")  # File from the DSA calculation step\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "\n",
    "# Step 2: Extract True Labels from the test dataset\n",
    "true_labels = [entry[\"label\"] for entry in test_data]\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 3: Add Failure Column\n",
    "df[\"is_failure\"] = df[\"predicted_label\"] != df[\"true_label\"]\n",
    "\n",
    "# Step 4: Ensure 'dsa_score' column exists\n",
    "if \"dsa_score\" not in df.columns:\n",
    "    raise ValueError(\"The dataset must include a 'dsa_score' column with DSA scores.\")\n",
    "\n",
    "# Step 5: Calculate correlations\n",
    "pearson_corr, pearson_p = pearsonr(df[\"dsa_score\"], df[\"is_failure\"])\n",
    "spearman_corr, spearman_p = spearmanr(df[\"dsa_score\"], df[\"is_failure\"])\n",
    "\n",
    "# Step 6: Display results\n",
    "print(f\"Pearson Correlation between DSA score and system failure: {pearson_corr:.4f} (p-value: {pearson_p:.4e})\")\n",
    "print(f\"Spearman Correlation between DSA score and system failure: {spearman_corr:.4f} (p-value: {spearman_p:.4e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043b6e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example confidence_score: 0.5583972930908203\n",
      "Error while calculating prediction margin: Invalid confidence scores: 0.5583972930908203\n",
      "Problematic rows:\n",
      "                                             input_text  predicted_label  \\\n",
      "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                1   \n",
      "1     static int qcow2_change_backing_file(BlockDriv...                0   \n",
      "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                0   \n",
      "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                1   \n",
      "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                0   \n",
      "...                                                 ...              ...   \n",
      "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                1   \n",
      "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                0   \n",
      "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                0   \n",
      "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                0   \n",
      "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                0   \n",
      "\n",
      "      confidence_score  \n",
      "0             0.558397  \n",
      "1             0.771769  \n",
      "2             0.663211  \n",
      "3             0.951676  \n",
      "4             0.526273  \n",
      "...                ...  \n",
      "2727          0.594357  \n",
      "2728          0.925011  \n",
      "2729          0.584445  \n",
      "2730          0.779009  \n",
      "2731          0.848445  \n",
      "\n",
      "[2732 rows x 3 columns]\n",
      "Updated dataset saved as 'test_predictions_with_aux_vars.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")  # Ensure this file contains \"confidence_score\" column\n",
    "\n",
    "# Step 2: Parse Confidence Scores\n",
    "# If confidence scores are in a single column as lists/strings, parse them\n",
    "if isinstance(df[\"confidence_score\"].iloc[0], str):\n",
    "    df[\"confidence_score\"] = df[\"confidence_score\"].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Debugging: Check the structure of the first row of confidence_score\n",
    "print(\"Example confidence_score:\", df[\"confidence_score\"].iloc[0])\n",
    "\n",
    "# Step 3: Calculate Prediction Margin\n",
    "def calculate_margin(confidences):\n",
    "    if not isinstance(confidences, (list, np.ndarray)) or len(confidences) < 2:\n",
    "        raise ValueError(f\"Invalid confidence scores: {confidences}\")\n",
    "    sorted_confidences = np.sort(confidences)[::-1]  # Sort in descending order\n",
    "    return sorted_confidences[0] - sorted_confidences[1]  # Difference between highest and second-highest confidence\n",
    "\n",
    "try:\n",
    "    df[\"prediction_margin\"] = df[\"confidence_score\"].apply(calculate_margin)\n",
    "except Exception as e:\n",
    "    print(\"Error while calculating prediction margin:\", e)\n",
    "    # Debugging: Print problematic rows\n",
    "    problematic_rows = df[df[\"confidence_score\"].apply(lambda x: not isinstance(x, (list, np.ndarray)) or len(x) < 2)]\n",
    "    print(\"Problematic rows:\")\n",
    "    print(problematic_rows)\n",
    "\n",
    "# Step 4: Calculate Variance of Probabilities\n",
    "try:\n",
    "    df[\"probability_variance\"] = df[\"confidence_score\"].apply(np.var)\n",
    "except Exception as e:\n",
    "    print(\"Error while calculating probability variance:\", e)\n",
    "\n",
    "# Step 5: Save Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_aux_vars.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_aux_vars.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95eda269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as 'test_predictions_with_failure_flag.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_75317/2369620185.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with the correct file path\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the updated dataset\n",
    "df = pd.read_csv(\"test_predictions_with_aux_vars.csv\")  # Replace with the correct file name\n",
    "\n",
    "# Load the original test data to get true labels\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with the correct file path\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels\n",
    "\n",
    "# Add true labels to the DataFrame\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Add 'is_failure' column\n",
    "df[\"is_failure\"] = df[\"predicted_label\"] != df[\"true_label\"]\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"test_predictions_with_failure_flag.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_failure_flag.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d209a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved with 'prediction_margin'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"test_predictions_with_failure_flag.csv\")\n",
    "\n",
    "# Ensure \"confidence_score\" exists\n",
    "if \"confidence_score\" not in df.columns:\n",
    "    raise ValueError(\"The dataset must include a 'confidence_score' column.\")\n",
    "\n",
    "# Calculate prediction margin\n",
    "df[\"prediction_margin\"] = df[\"confidence_score\"].apply(lambda x: np.abs(x - (1 - x)))\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"test_predictions_with_margin.csv\", index=False)\n",
    "print(\"Updated dataset saved with 'prediction_margin'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeef6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as 'test_predictions_with_updated_aux.csv'.\n",
      "Correlation Analysis Results:\n",
      "Auxiliary Variable: prediction_margin\n",
      "  Pearson Correlation: -0.2779\n",
      "  Pearson P-value: 0.0000\n",
      "  Spearman Correlation: -0.2543\n",
      "  Spearman P-value: 0.0000\n",
      "\n",
      "Auxiliary Variable: confidence_score\n",
      "  Pearson Correlation: -0.2779\n",
      "  Pearson P-value: 0.0000\n",
      "  Spearman Correlation: -0.2543\n",
      "  Spearman P-value: 0.0000\n",
      "\n",
      "Auxiliary Variable: prediction_entropy\n",
      "  Pearson Correlation: 0.2811\n",
      "  Pearson P-value: 0.0000\n",
      "  Spearman Correlation: 0.2543\n",
      "  Spearman P-value: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"test_predictions_with_entropy.csv\")\n",
    "\n",
    "# Step 2: Add 'is_failure' Column\n",
    "df[\"is_failure\"] = df[\"predicted_label\"] != df[\"true_label\"]\n",
    "\n",
    "# Step 3: Add New Auxiliary Variables\n",
    "# Calculate prediction_margin\n",
    "def calculate_margin(confidence_score):\n",
    "    sorted_confidences = np.array([confidence_score, 1 - confidence_score])  # For binary classification\n",
    "    sorted_confidences.sort()  # Sort in ascending order\n",
    "    return sorted_confidences[-1] - sorted_confidences[-2]  # Difference between top two confidences\n",
    "\n",
    "df[\"prediction_margin\"] = df[\"confidence_score\"].apply(calculate_margin)\n",
    "\n",
    "# Calculate probability_variance\n",
    "df[\"probability_variance\"] = df[\"confidence_score\"].apply(lambda x: np.var([x, 1 - x]))\n",
    "\n",
    "# Step 4: Perform Correlation Analysis\n",
    "results = {}\n",
    "for aux_var in [\"prediction_margin\", \"confidence_score\", \"prediction_entropy\"]:\n",
    "    pearson_corr, pearson_p = pearsonr(df[aux_var], df[\"is_failure\"])\n",
    "    spearman_corr, spearman_p = spearmanr(df[aux_var], df[\"is_failure\"])\n",
    "    results[aux_var] = {\n",
    "        \"Pearson Correlation\": pearson_corr,\n",
    "        \"Pearson P-value\": pearson_p,\n",
    "        \"Spearman Correlation\": spearman_corr,\n",
    "        \"Spearman P-value\": spearman_p,\n",
    "    }\n",
    "\n",
    "# Step 5: Save the Updated Dataset\n",
    "df.to_csv(\"test_predictions_with_updated_aux.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_updated_aux.csv'.\")\n",
    "\n",
    "# Display Correlation Results\n",
    "print(\"Correlation Analysis Results:\")\n",
    "for aux_var, stats in results.items():\n",
    "    print(f\"Auxiliary Variable: {aux_var}\")\n",
    "    for stat_name, value in stats.items():\n",
    "        print(f\"  {stat_name}: {value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa7d6227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability variance added to the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "df = pd.read_csv(\"test_predictions_with_entropy.csv\")  # Ensure this file exists\n",
    "\n",
    "# Step 2: Add Probability Variance\n",
    "# Assuming \"confidence_score\" is a single confidence value, we compute the variance as:\n",
    "# For binary classification, variance = (p * (1-p))\n",
    "df[\"probability_variance\"] = df[\"confidence_score\"] * (1 - df[\"confidence_score\"])\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"test_predictions_with_entropy.csv\", index=False)\n",
    "print(\"Probability variance added to the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9419de52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>true_label</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>prediction_entropy</th>\n",
       "      <th>probability_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558397</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990138</td>\n",
       "      <td>0.246590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.774915</td>\n",
       "      <td>0.176142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663211</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.921713</td>\n",
       "      <td>0.223362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951676</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.279236</td>\n",
       "      <td>0.045989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526273</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998007</td>\n",
       "      <td>0.249310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.974156</td>\n",
       "      <td>0.241097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384273</td>\n",
       "      <td>0.069366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584445</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.979326</td>\n",
       "      <td>0.242869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779009</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.761973</td>\n",
       "      <td>0.172154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.613718</td>\n",
       "      <td>0.128586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  predicted_label  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                1   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...                0   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                0   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                1   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                0   \n",
       "...                                                 ...              ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                1   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                0   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                0   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                0   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                0   \n",
       "\n",
       "      confidence_score  true_label  is_correct  prediction_entropy  \\\n",
       "0             0.558397           1        True            0.990138   \n",
       "1             0.771769           1       False            0.774915   \n",
       "2             0.663211           1       False            0.921713   \n",
       "3             0.951676           1        True            0.279236   \n",
       "4             0.526273           1       False            0.998007   \n",
       "...                ...         ...         ...                 ...   \n",
       "2727          0.594357           1        True            0.974156   \n",
       "2728          0.925011           1       False            0.384273   \n",
       "2729          0.584445           1       False            0.979326   \n",
       "2730          0.779009           0        True            0.761973   \n",
       "2731          0.848445           1       False            0.613718   \n",
       "\n",
       "      probability_variance  \n",
       "0                 0.246590  \n",
       "1                 0.176142  \n",
       "2                 0.223362  \n",
       "3                 0.045989  \n",
       "4                 0.249310  \n",
       "...                    ...  \n",
       "2727              0.241097  \n",
       "2728              0.069366  \n",
       "2729              0.242869  \n",
       "2730              0.172154  \n",
       "2731              0.128586  \n",
       "\n",
       "[2732 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0795cb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis Results for Probability Variance with Correctness:\n",
      "  Pearson Correlation: -0.2814\n",
      "  Pearson P-value: 6.7212e-51\n",
      "  Spearman Correlation: -0.2543\n",
      "  Spearman P-value: 1.4051e-41\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = [\"probability_variance\", \"is_correct\"]\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"The dataset must include a '{col}' column.\")\n",
    "\n",
    "# Calculate correlations\n",
    "pearson_corr, pearson_p = pearsonr(df[\"probability_variance\"], df[\"is_correct\"])\n",
    "spearman_corr, spearman_p = spearmanr(df[\"probability_variance\"], df[\"is_correct\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"Correlation Analysis Results for Probability Variance with Correctness:\")\n",
    "print(f\"  Pearson Correlation: {pearson_corr:.4f}\")\n",
    "print(f\"  Pearson P-value: {pearson_p:.4e}\")\n",
    "print(f\"  Spearman Correlation: {spearman_corr:.4f}\")\n",
    "print(f\"  Spearman P-value: {spearman_p:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "122e6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as 'test_predictions_with_top_k_margin.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "df = pd.read_csv(\"test_predictions_with_entropy.csv\")  # Ensure this file exists\n",
    "\n",
    "# Step 2: Parse Confidence Scores\n",
    "# Check if `confidence_score` is already a list or array\n",
    "def parse_confidence_scores(row):\n",
    "    if isinstance(row[\"confidence_score\"], str):\n",
    "        return np.array([float(x) for x in row[\"confidence_score\"].split(\",\")])\n",
    "    elif isinstance(row[\"confidence_score\"], (list, np.ndarray)):\n",
    "        return np.array(row[\"confidence_score\"])\n",
    "    else:\n",
    "        return np.array([row[\"confidence_score\"]])\n",
    "\n",
    "df[\"parsed_confidence_scores\"] = df.apply(parse_confidence_scores, axis=1)\n",
    "\n",
    "# Step 3: Calculate Top-k Confidence Margin\n",
    "def calculate_top_k_margin(confidences, k=3):\n",
    "    \"\"\"\n",
    "    Calculate the margin between the top-k confidences.\n",
    "    :param confidences: Array of confidence scores.\n",
    "    :param k: Number of top confidences to consider.\n",
    "    :return: Margin between the kth and (k+1)th highest confidences.\n",
    "    \"\"\"\n",
    "    sorted_confidences = np.sort(confidences)[::-1]  # Sort in descending order\n",
    "    if len(sorted_confidences) >= k + 1:\n",
    "        return sorted_confidences[k - 1] - sorted_confidences[k]\n",
    "    return 0.0  # If less than k confidences, return 0\n",
    "\n",
    "# Calculate Top-3 Margin (You can change `k` as needed)\n",
    "df[\"top_3_margin\"] = df[\"parsed_confidence_scores\"].apply(calculate_top_k_margin, k=3)\n",
    "\n",
    "# Step 4: Save the Updated Dataset\n",
    "df.drop(columns=[\"parsed_confidence_scores\"], inplace=True)  # Clean up temporary column\n",
    "df.to_csv(\"test_predictions_with_top_k_margin.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_top_k_margin.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23b58d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in dataset:\n",
      "input_text              0\n",
      "predicted_label         0\n",
      "confidence_score        0\n",
      "true_label              0\n",
      "is_correct              0\n",
      "prediction_entropy      0\n",
      "probability_variance    0\n",
      "top_3_margin            0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in 'top_3_margin':\n",
      "[0.]\n",
      "\n",
      "Unique values in 'is_correct':\n",
      "[ True False]\n",
      "\n",
      "Data types:\n",
      "top_3_margin    float64\n",
      "is_correct         bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d41e8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.558397\n",
      "1    0.771769\n",
      "2    0.663211\n",
      "3    0.951676\n",
      "4    0.526273\n",
      "Name: confidence_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"confidence_score\"].head())  # Inspect the original confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1126574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction_margin\"] = abs(df[\"confidence_score\"] - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ca420bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis Results:\n",
      "Pearson Correlation: 0.2779 (p-value: 1.2219e-49)\n",
      "Spearman Correlation: 0.2543 (p-value: 1.4051e-41)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "pearson_corr, pearson_p = pearsonr(df[\"prediction_margin\"], df[\"is_correct\"])\n",
    "spearman_corr, spearman_p = spearmanr(df[\"prediction_margin\"], df[\"is_correct\"])\n",
    "\n",
    "print(\"Correlation Analysis Results:\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f} (p-value: {pearson_p:.4e})\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7e6319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./improved_finetuned_codebert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_8177/2681939399.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_8177/2681939399.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|                 | 57/683 [01:13<13:27,  1.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Step 4: Extract embeddings\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting embeddings for training set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m train_embeddings \u001b[38;5;241m=\u001b[39m extract_embeddings(train_texts)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting embeddings for test set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m test_embeddings \u001b[38;5;241m=\u001b[39m extract_embeddings(test_texts)\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36mextract_embeddings\u001b[0;34m(texts, batch_size, layer)\u001b[0m\n\u001b[1;32m     32\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states[layer]  \u001b[38;5;66;03m# Use second-to-last layer\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m         batch_embeddings \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Mean pooling\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(embeddings)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Step 1: Load the fine-tuned model and tokenizer\n",
    "model_path = \"./improved_finetuned_codebert\"  # Replace with your model path\n",
    "model = AutoModel.from_pretrained(model_path).to(device)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Step 2: Load tokenized datasets\n",
    "train_data = torch.load(\"tokenized_train.pt\")  # Replace with your file path\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with your file path\n",
    "\n",
    "# Decode texts from tokenized datasets\n",
    "train_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in train_data]\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "\n",
    "# Step 3: Function to extract embeddings\n",
    "def extract_embeddings(texts, batch_size=32, layer=-2):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting embeddings\"):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[layer]  # Use second-to-last layer\n",
    "            batch_embeddings = hidden_states.mean(dim=1).cpu().numpy()  # Mean pooling\n",
    "            embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Step 4: Extract embeddings\n",
    "print(\"Extracting embeddings for training set...\")\n",
    "train_embeddings = extract_embeddings(train_texts)\n",
    "\n",
    "print(\"Extracting embeddings for test set...\")\n",
    "test_embeddings = extract_embeddings(test_texts)\n",
    "\n",
    "# Step 5: Compute cosine similarity\n",
    "def calculate_cosine_similarity(test_embeddings, train_embeddings, k=5):\n",
    "    cosine_similarities = []\n",
    "    for test_emb in tqdm(test_embeddings, desc=\"Calculating cosine similarity\"):\n",
    "        similarities = cosine_similarity([test_emb], train_embeddings)[0]\n",
    "        top_k_similarities = np.sort(similarities)[-k:]  # Get top-k similarities\n",
    "        cosine_similarities.append(np.mean(top_k_similarities))  # Take mean of top-k\n",
    "    return cosine_similarities\n",
    "\n",
    "print(\"Calculating cosine similarities...\")\n",
    "cosine_similarities = calculate_cosine_similarity(test_embeddings, train_embeddings)\n",
    "\n",
    "# Step 6: Prepare the test set DataFrame\n",
    "df = pd.read_csv(\"test_predictions_with_confidence.csv\")  # Ensure file exists\n",
    "test_true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels\n",
    "\n",
    "# Add auxiliary information\n",
    "df[\"true_label\"] = test_true_labels\n",
    "df[\"cosine_similarity\"] = cosine_similarities\n",
    "df[\"is_correct\"] = df[\"predicted_label\"] == df[\"true_label\"]\n",
    "\n",
    "# Step 7: Save updated dataset\n",
    "df.to_csv(\"test_predictions_with_all_metrics.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_predictions_with_all_metrics.csv'.\")\n",
    "\n",
    "# Step 8: Correlation Analysis\n",
    "def correlation_analysis(df, aux_columns, target_column=\"is_correct\"):\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    results = {}\n",
    "    for aux_col in aux_columns:\n",
    "        pearson_corr, pearson_p = pearsonr(df[aux_col], df[target_column])\n",
    "        spearman_corr, spearman_p = spearmanr(df[aux_col], df[target_column])\n",
    "        results[aux_col] = {\n",
    "            \"Pearson Correlation\": pearson_corr,\n",
    "            \"Pearson P-value\": pearson_p,\n",
    "            \"Spearman Correlation\": spearman_corr,\n",
    "            \"Spearman P-value\": spearman_p,\n",
    "        }\n",
    "    return results\n",
    "\n",
    "aux_columns = [\"confidence_score\", \"cosine_similarity\"]\n",
    "correlation_results = correlation_analysis(df, aux_columns)\n",
    "\n",
    "print(\"Correlation Results:\")\n",
    "for metric, stats in correlation_results.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e30acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558397</td>\n",
       "      <td>0.955889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.870490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663211</td>\n",
       "      <td>0.997331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951676</td>\n",
       "      <td>0.978289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526273</td>\n",
       "      <td>0.996433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>0.998611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>0.893975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584445</td>\n",
       "      <td>0.913298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779009</td>\n",
       "      <td>0.901658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>0.972240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  predicted_label  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                1   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...                0   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                0   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                1   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                0   \n",
       "...                                                 ...              ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                1   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                0   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                0   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                0   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                0   \n",
       "\n",
       "      confidence_score  cosine_similarity  \n",
       "0             0.558397           0.955889  \n",
       "1             0.771769           0.870490  \n",
       "2             0.663211           0.997331  \n",
       "3             0.951676           0.978289  \n",
       "4             0.526273           0.996433  \n",
       "...                ...                ...  \n",
       "2727          0.594357           0.998611  \n",
       "2728          0.925011           0.893975  \n",
       "2729          0.584445           0.913298  \n",
       "2730          0.779009           0.901658  \n",
       "2731          0.848445           0.972240  \n",
       "\n",
       "[2732 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c6f7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved as 'test_predictions_with_cosine_similarity_and_labels.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_75317/1089940041.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Replace with the correct path\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the updated dataset\n",
    "df = pd.read_csv(\"test_predictions_with_cosine_similarity.csv\")\n",
    "\n",
    "# Step 2: Load the tokenized test data to extract true labels\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Replace with the correct path\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels\n",
    "\n",
    "# Step 3: Add true labels to the DataFrame\n",
    "df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 4: Add Correctness Column\n",
    "df[\"is_correct\"] = df[\"predicted_label\"] == df[\"true_label\"]\n",
    "\n",
    "# Save the updated dataset for future use\n",
    "df.to_csv(\"test_predictions_with_cosine_similarity_and_labels.csv\", index=False)\n",
    "\n",
    "print(\"Updated dataset saved as 'test_predictions_with_cosine_similarity_and_labels.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dec7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting radon\n",
      "  Obtaining dependency information for radon from https://files.pythonhosted.org/packages/93/f7/d00d9b4a0313a6be3a3e0818e6375e15da6d7076f4ae47d1324e7ca986a1/radon-6.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading radon-6.0.1-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting mando<0.8,>=0.6 (from radon)\n",
      "  Obtaining dependency information for mando<0.8,>=0.6 from https://files.pythonhosted.org/packages/d2/f0/834e479e47e499b6478e807fb57b31cc2db696c4db30557bb6f5aea4a90b/mando-0.7.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading mando-0.7.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from mando<0.8,>=0.6->radon) (1.17.0)\n",
      "Downloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
      "Installing collected packages: mando, radon\n",
      "Successfully installed mando-0.7.1 radon-6.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4ff6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis Results:\n",
      "Pearson Correlation: 0.0293 (p-value: 1.2570e-01)\n",
      "Spearman Correlation: 0.0380 (p-value: 4.6868e-02)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Perform Correlation Analysis\n",
    "required_columns = [\"cosine_similarity\", \"is_correct\"]\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"The dataset must include a '{col}' column.\")\n",
    "\n",
    "pearson_corr, pearson_p = pearsonr(df[\"cosine_similarity\"], df[\"is_correct\"])\n",
    "spearman_corr, spearman_p = spearmanr(df[\"cosine_similarity\"], df[\"is_correct\"])\n",
    "\n",
    "# Step 6: Display results\n",
    "print(\"Correlation Analysis Results:\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f} (p-value: {pearson_p:.4e})\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f2d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliasgari/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_9354/1332296137.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for each code snippet...\n",
      "Metrics added to dataset and saved as 'test_metrics.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from radon.complexity import cc_visit\n",
    "import ast\n",
    "import subprocess\n",
    "\n",
    "# Load Fine-Tuned Model Tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load Test Dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "\n",
    "# Create a DataFrame for Metrics\n",
    "df = pd.DataFrame({\"input_text\": test_texts})\n",
    "\n",
    "# Metrics Calculation\n",
    "def calculate_cyclomatic_complexity(code):\n",
    "    try:\n",
    "        results = cc_visit(code)\n",
    "        return sum(result.complexity for result in results)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def count_lines_of_code(code):\n",
    "    return len(code.splitlines())\n",
    "\n",
    "def count_functions(code):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        return sum(isinstance(node, ast.FunctionDef) for node in ast.walk(tree))\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def count_imports(code):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        return sum(isinstance(node, (ast.Import, ast.ImportFrom)) for node in ast.walk(tree))\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def count_variables(code):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        return sum(isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store) for node in ast.walk(tree))\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def calculate_comment_density(code):\n",
    "    lines = code.splitlines()\n",
    "    comments = sum(1 for line in lines if line.strip().startswith(\"#\"))\n",
    "    return comments / len(lines) if len(lines) > 0 else 0\n",
    "\n",
    "def run_bandit_on_code(code):\n",
    "    try:\n",
    "        with open(\"temp_code.py\", \"w\") as f:\n",
    "            f.write(code)\n",
    "        result = subprocess.run([\"bandit\", \"-f\", \"json\", \"temp_code.py\"], capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Apply Metrics to Dataset\n",
    "print(\"Calculating metrics for each code snippet...\")\n",
    "df[\"cyclomatic_complexity\"] = df[\"input_text\"].apply(calculate_cyclomatic_complexity)\n",
    "df[\"lines_of_code\"] = df[\"input_text\"].apply(count_lines_of_code)\n",
    "df[\"function_count\"] = df[\"input_text\"].apply(count_functions)\n",
    "df[\"import_count\"] = df[\"input_text\"].apply(count_imports)\n",
    "df[\"variable_count\"] = df[\"input_text\"].apply(count_variables)\n",
    "df[\"comment_density\"] = df[\"input_text\"].apply(calculate_comment_density)\n",
    "df[\"security_findings\"] = df[\"input_text\"].apply(run_bandit_on_code)\n",
    "\n",
    "# Save Updated Dataset\n",
    "df.to_csv(\"test_metrics.csv\", index=False)\n",
    "print(\"Metrics added to dataset and saved as 'test_metrics.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33166bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>None</td>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>None</td>\n",
       "      <td>33</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text cyclomatic_complexity  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...                  None   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...                  None   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...                  None   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...                  None   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...                  None   \n",
       "...                                                 ...                   ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...                  None   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...                  None   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...                  None   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...                  None   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...                  None   \n",
       "\n",
       "      lines_of_code function_count import_count variable_count  \\\n",
       "0                53           None         None           None   \n",
       "1                 9           None         None           None   \n",
       "2                45           None         None           None   \n",
       "3                27           None         None           None   \n",
       "4                51           None         None           None   \n",
       "...             ...            ...          ...            ...   \n",
       "2727             37           None         None           None   \n",
       "2728             13           None         None           None   \n",
       "2729             35           None         None           None   \n",
       "2730             31           None         None           None   \n",
       "2731             33           None         None           None   \n",
       "\n",
       "      comment_density security_findings  \n",
       "0                 0.0              None  \n",
       "1                 0.0              None  \n",
       "2                 0.0              None  \n",
       "3                 0.0              None  \n",
       "4                 0.0              None  \n",
       "...               ...               ...  \n",
       "2727              0.0              None  \n",
       "2728              0.0              None  \n",
       "2729              0.0              None  \n",
       "2730              0.0              None  \n",
       "2731              0.0              None  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae15bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lizard\n",
      "  Obtaining dependency information for lizard from https://files.pythonhosted.org/packages/b8/37/8eff5380bd28768529a64391c9ca1f475e7f7308a0b4226f94dda3971fbc/lizard-1.17.13-py2.py3-none-any.whl.metadata\n",
      "  Downloading lizard-1.17.13-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pygments in /Users/aliasgari/anaconda3/lib/python3.11/site-packages (from lizard) (2.18.0)\n",
      "Downloading lizard-1.17.13-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lizard\n",
      "Successfully installed lizard-1.17.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5203700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.13\r\n"
     ]
    }
   ],
   "source": [
    "!lizard --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858e2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updating Homebrew...\u001b[0m\n",
      "Adjust how often this is run with HOMEBREW_AUTO_UPDATE_SECS or disable with\n",
      "HOMEBREW_NO_AUTO_UPDATE. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "\n",
      "This repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'post-checkout' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks').\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "aws-c-auth                 idsgrep                    sequin\n",
      "aws-c-mqtt                 imgp                       sfsexp\n",
      "aws-c-s3                   libsidplayfp               spytrap-adb\n",
      "aws-crt-cpp                libunicode                 templ\n",
      "azure-core-cpp             macmon                     tenere\n",
      "cargo-chef                 mago                       versitygw\n",
      "cobra-cli                  poselib                    weaviate\n",
      "fairy-stockfish            protoc-gen-grpc-java       weaviate-cli\n",
      "fzf-make                   render                     wgo\n",
      "graphql-inspector          repren                     zsh-f-sy-h\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
      "bananas                                  font-playwrite-hu-guides\n",
      "dorico                                   font-playwrite-id-guides\n",
      "font-agu-display                         font-playwrite-ie-guides\n",
      "font-badeen-display                      font-playwrite-in-guides\n",
      "font-bravura                             font-playwrite-is-guides\n",
      "font-ibm-plex-sans-sc                    font-playwrite-it-moderna-guides\n",
      "font-kanchenjunga                        font-playwrite-it-trad-guides\n",
      "font-playwrite-ar-guides                 font-playwrite-mx-guides\n",
      "font-playwrite-at-guides                 font-playwrite-ng-modern-guides\n",
      "font-playwrite-au-nsw-guides             font-playwrite-nl-guides\n",
      "font-playwrite-au-qld-guides             font-playwrite-no-guides\n",
      "font-playwrite-au-sa-guides              font-playwrite-nz-guides\n",
      "font-playwrite-au-tas-guides             font-playwrite-pe-guides\n",
      "font-playwrite-au-vic-guides             font-playwrite-pl-guides\n",
      "font-playwrite-be-vlg-guides             font-playwrite-pt-guides\n",
      "font-playwrite-be-wal-guides             font-playwrite-ro-guides\n",
      "font-playwrite-br-guides                 font-playwrite-sk-guides\n",
      "font-playwrite-ca-guides                 font-playwrite-tz-guides\n",
      "font-playwrite-cl-guides                 font-playwrite-us-modern-guides\n",
      "font-playwrite-co-guides                 font-playwrite-us-trad-guides\n",
      "font-playwrite-cu-guides                 font-playwrite-vn-guides\n",
      "font-playwrite-cz-guides                 font-playwrite-za-guides\n",
      "font-playwrite-de-grund-guides           font-tamzen\n",
      "font-playwrite-de-la-guides              halion-sonic\n",
      "font-playwrite-de-sas-guides             meridiem\n",
      "font-playwrite-de-va-guides              nvidia-nsight-systems\n",
      "font-playwrite-dk-loopet-guides          octarine\n",
      "font-playwrite-dk-uloopet-guides         restic-browser\n",
      "font-playwrite-es-deco-guides            steinberg-download-assistant\n",
      "font-playwrite-es-guides                 steinberg-library-manager\n",
      "font-playwrite-fr-moderne-guides         steinberg-mediabay\n",
      "font-playwrite-fr-trad-guides            supremo\n",
      "font-playwrite-gb-j-guides               sys-pc-tool\n",
      "font-playwrite-gb-s-guides               windsurf\n",
      "font-playwrite-hr-guides                 wizcli\n",
      "font-playwrite-hr-lijeva-guides\n",
      "\n",
      "You have \u001b[1m22\u001b[0m outdated formulae installed.\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/cppcheck/manifests/2.16.0\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for cppcheck: \u001b[32mpcre\u001b[39m and \u001b[32mtinyxml2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pcre/manifests/8.45\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mpcre\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pcre/blobs/sha256:fbc1ec29701c2\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/tinyxml2/manifests/10.0.0\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mtinyxml2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/tinyxml2/blobs/sha256:06a3ca5d8\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mcppcheck\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/cppcheck/blobs/sha256:bb3feb14a\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for cppcheck: \u001b[32mpcre\u001b[39m and \u001b[32mtinyxml2\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling cppcheck dependency: \u001b[32mpcre\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pcre/manifests/8.45\u001b[0m\n",
      "Already downloaded: /Users/aliasgari/Library/Caches/Homebrew/downloads/4a3bba0e8d1899c13ac3442d2c49df6c1999948bdc0943f2f179693257d82545--pcre-8.45.bottle_manifest.json\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring pcre--8.45.arm64_sonoma.bottle.tar.gz\u001b[0m\n",
      "  /opt/homebrew/Cellar/pcre/8.45: 205 files, 4.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling cppcheck dependency: \u001b[32mtinyxml2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/tinyxml2/manifests/10.0.0\u001b[0m\n",
      "Already downloaded: /Users/aliasgari/Library/Caches/Homebrew/downloads/b89d8dc0c55edc6ca1eae2b6115622730886e8acac7edabafc1bc386495b8030--tinyxml2-10.0.0.bottle_manifest.json\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring tinyxml2--10.0.0.arm64_sonoma.bottle.tar.gz\u001b[0m\n",
      "  /opt/homebrew/Cellar/tinyxml2/10.0.0: 14 files, 228KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mcppcheck\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring cppcheck--2.16.0.arm64_sonoma.bottle.tar.gz\u001b[0m\n",
      "  /opt/homebrew/Cellar/cppcheck/2.16.0: 85 files, 9.9MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup cppcheck`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
     ]
    }
   ],
   "source": [
    "! brew install cppcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1eaa3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cppcheck 2.16.0\r\n"
     ]
    }
   ],
   "source": [
    "!cppcheck --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d557d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard:  15%|        | 406/2732 [00:00<00:01, 2056.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 7: Not valid C function\n",
      "Skipping record 35: Not valid C function\n",
      "Skipping record 74: Not valid C function\n",
      "Skipping record 103: Not valid C function\n",
      "Skipping record 140: Not valid C function\n",
      "Skipping record 173: Not valid C function\n",
      "Skipping record 180: Not valid C function\n",
      "Skipping record 276: Not valid C function\n",
      "Skipping record 294: Not valid C function\n",
      "Skipping record 383: Not valid C function\n",
      "Skipping record 412: Not valid C function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard:  31%|       | 839/2732 [00:00<00:00, 2133.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 446: Not valid C function\n",
      "Skipping record 658: Not valid C function\n",
      "Skipping record 660: Not valid C function\n",
      "Skipping record 696: Not valid C function\n",
      "Skipping record 709: Not valid C function\n",
      "Skipping record 829: Not valid C function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard:  47%|    | 1279/2732 [00:00<00:00, 2167.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 884: Not valid C function\n",
      "Skipping record 897: Not valid C function\n",
      "Skipping record 899: Not valid C function\n",
      "Skipping record 901: Not valid C function\n",
      "Skipping record 1021: Not valid C function\n",
      "Skipping record 1085: Not valid C function\n",
      "Skipping record 1099: Not valid C function\n",
      "Skipping record 1111: Not valid C function\n",
      "Skipping record 1225: Not valid C function\n",
      "Skipping record 1237: Not valid C function\n",
      "Skipping record 1308: Not valid C function\n",
      "Skipping record 1314: Not valid C function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard:  64%|   | 1735/2732 [00:00<00:00, 2222.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 1388: Not valid C function\n",
      "Skipping record 1404: Not valid C function\n",
      "Skipping record 1424: Not valid C function\n",
      "Skipping record 1570: Not valid C function\n",
      "Skipping record 1577: Not valid C function\n",
      "Skipping record 1652: Not valid C function\n",
      "Skipping record 1654: Not valid C function\n",
      "Skipping record 1695: Not valid C function\n",
      "Skipping record 1736: Not valid C function\n",
      "Skipping record 1739: Not valid C function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard:  88%| | 2417/2732 [00:01<00:00, 2254.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 2018: Not valid C function\n",
      "Skipping record 2038: Not valid C function\n",
      "Skipping record 2123: Not valid C function\n",
      "Skipping record 2124: Not valid C function\n",
      "Skipping record 2169: Not valid C function\n",
      "Skipping record 2224: Not valid C function\n",
      "Skipping record 2233: Not valid C function\n",
      "Skipping record 2246: Not valid C function\n",
      "Skipping record 2295: Not valid C function\n",
      "Skipping record 2393: Not valid C function\n",
      "Skipping record 2450: Not valid C function\n",
      "Skipping record 2453: Not valid C function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with Lizard: 100%|| 2732/2732 [00:01<00:00, 2207.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping record 2498: Not valid C function\n",
      "Skipping record 2501: Not valid C function\n",
      "Skipping record 2505: Not valid C function\n",
      "Skipping record 2570: Not valid C function\n",
      "Skipping record 2610: Not valid C function\n",
      "Skipping record 2611: Not valid C function\n",
      "Skipping record 2634: Not valid C function\n",
      "Skipping record 2648: Not valid C function\n",
      "Skipping record 2678: Not valid C function\n",
      "Metrics extracted and saved as 'test_code_metrics_with_validation.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import lizard\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the test dataset\n",
    "df = pd.read_csv(\"test_code_metrics.csv\")  # File created earlier\n",
    "\n",
    "# Directory for temporary files\n",
    "temp_dir = \"./temp_code_files\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Function to validate code snippets\n",
    "def is_valid_c_function(code):\n",
    "    return \"{\" in code and (\"int\" in code or \"void\" in code or \"static\" in code)\n",
    "\n",
    "# Extract metrics for each input_text\n",
    "metrics = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing code with Lizard\"):\n",
    "    if not is_valid_c_function(row[\"input_text\"]):\n",
    "        print(f\"Skipping record {i}: Not valid C function\")\n",
    "        metrics.append({\n",
    "            \"file_index\": i,\n",
    "            \"function_name\": None,\n",
    "            \"cyclomatic_complexity\": None,\n",
    "            \"lines_of_code\": None,\n",
    "            \"parameter_count\": None\n",
    "        })\n",
    "        continue  # Skip invalid code\n",
    "    \n",
    "    # Save each input_text to a temporary .c file\n",
    "    file_path = os.path.join(temp_dir, f\"snippet_{i}.c\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(row[\"input_text\"])\n",
    "    \n",
    "    # Analyze the file with Lizard\n",
    "    analysis = lizard.analyze_file(file_path)\n",
    "    \n",
    "    # Collect metrics\n",
    "    if analysis.function_list:  # Functions in the file\n",
    "        for func in analysis.function_list:\n",
    "            metrics.append({\n",
    "                \"file_index\": i,\n",
    "                \"function_name\": func.name,\n",
    "                \"cyclomatic_complexity\": func.cyclomatic_complexity,\n",
    "                \"lines_of_code\": func.length,\n",
    "                \"parameter_count\": func.parameter_count\n",
    "            })\n",
    "    else:  # No functions, but valid code\n",
    "        metrics.append({\n",
    "            \"file_index\": i,\n",
    "            \"function_name\": None,\n",
    "            \"cyclomatic_complexity\": None,\n",
    "            \"lines_of_code\": analysis.nloc,\n",
    "            \"parameter_count\": None\n",
    "        })\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "# Handle NaN values (e.g., fill with 0 or drop rows)\n",
    "df_metrics.fillna(0, inplace=True)\n",
    "\n",
    "# Aggregate metrics back into the original DataFrame\n",
    "for col in [\"cyclomatic_complexity\", \"lines_of_code\"]:\n",
    "    df[col] = df_metrics.groupby(\"file_index\")[col].mean()\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"test_code_metrics_with_validation.csv\", index=False)\n",
    "print(\"Metrics extracted and saved as 'test_code_metrics_with_validation.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce23508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...   \n",
       "...                                                 ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...   \n",
       "\n",
       "      cyclomatic_complexity  lines_of_code  function_count  import_count  \\\n",
       "0                       7.0           53.0             NaN           NaN   \n",
       "1                       1.0            9.0             NaN           NaN   \n",
       "2                       0.0           22.0             NaN           NaN   \n",
       "3                       3.0           27.0             NaN           NaN   \n",
       "4                       0.0           23.0             NaN           NaN   \n",
       "...                     ...            ...             ...           ...   \n",
       "2727                    0.0           18.0             NaN           NaN   \n",
       "2728                    1.0           13.0             NaN           NaN   \n",
       "2729                    3.0           35.0             NaN           NaN   \n",
       "2730                    4.0           31.0             NaN           NaN   \n",
       "2731                    0.0           14.0             NaN           NaN   \n",
       "\n",
       "      variable_count  comment_density  security_findings  \n",
       "0                NaN              NaN                NaN  \n",
       "1                NaN              NaN                NaN  \n",
       "2                NaN              NaN                NaN  \n",
       "3                NaN              NaN                NaN  \n",
       "4                NaN              NaN                NaN  \n",
       "...              ...              ...                ...  \n",
       "2727             NaN              NaN                NaN  \n",
       "2728             NaN              NaN                NaN  \n",
       "2729             NaN              NaN                NaN  \n",
       "2730             NaN              NaN                NaN  \n",
       "2731             NaN              NaN                NaN  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "885601d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...   \n",
       "...                                                 ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...   \n",
       "\n",
       "      cyclomatic_complexity  lines_of_code  function_count  import_count  \\\n",
       "0                       7.0           53.0             NaN           NaN   \n",
       "1                       1.0            9.0             NaN           NaN   \n",
       "2                       0.0           22.0             NaN           NaN   \n",
       "3                       3.0           27.0             NaN           NaN   \n",
       "4                       0.0           23.0             NaN           NaN   \n",
       "...                     ...            ...             ...           ...   \n",
       "2727                    0.0           18.0             NaN           NaN   \n",
       "2728                    1.0           13.0             NaN           NaN   \n",
       "2729                    3.0           35.0             NaN           NaN   \n",
       "2730                    4.0           31.0             NaN           NaN   \n",
       "2731                    0.0           14.0             NaN           NaN   \n",
       "\n",
       "      variable_count  comment_density  security_findings  \n",
       "0                NaN              NaN                NaN  \n",
       "1                NaN              NaN                NaN  \n",
       "2                NaN              NaN                NaN  \n",
       "3                NaN              NaN                NaN  \n",
       "4                NaN              NaN                NaN  \n",
       "...              ...              ...                ...  \n",
       "2727             NaN              NaN                NaN  \n",
       "2728             NaN              NaN                NaN  \n",
       "2729             NaN              NaN                NaN  \n",
       "2730             NaN              NaN                NaN  \n",
       "2731             NaN              NaN                NaN  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b77f3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       static void simple_whitespace(void)\\n\\n{\\n\\n  ...\n",
      "4       static int32_t bmdma_prepare_buf(IDEDMA *dma, ...\n",
      "5       int pcistb_service_call(S390CPU *cpu, uint8_t ...\n",
      "6       static void do_interrupt_protected(CPUX86State...\n",
      "8       static int read_thread(void *arg)\\n\\n{\\n\\n    ...\n",
      "                              ...                        \n",
      "2722    int ff_jni_exception_get_summary(JNIEnv *env, ...\n",
      "2723    static void file_completion(const char *input)...\n",
      "2726    void dsputil_init_arm(DSPContext* c, AVCodecCo...\n",
      "2727    static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...\n",
      "2731    int ff_h264_alloc_tables(H264Context *h){\\n\\n ...\n",
      "Name: input_text, Length: 1373, dtype: object\n"
     ]
    }
   ],
   "source": [
    "missing_metrics = df[df[\"cyclomatic_complexity\"].isna()]\n",
    "print(missing_metrics[\"input_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de1c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_c_function(code):\n",
    "    return \"{\" in code and (\"int\" in code or \"void\" in code or \"static\" in code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "722d235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with CppCheck: 100%|| 2732/2732 [00:34<00:00, 78.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security findings extracted and saved as 'test_code_metrics_with_cppcheck.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prepare for CppCheck Analysis\n",
    "cppcheck_data = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing code with CppCheck\"):\n",
    "    # Save each input_text to a temporary .c file\n",
    "    file_path = os.path.join(temp_dir, f\"snippet_{i}.c\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(row[\"input_text\"])\n",
    "    \n",
    "    # Run CppCheck on the file\n",
    "    result = subprocess.run(\n",
    "        [\"cppcheck\", \"--enable=all\", \"--xml\", file_path],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Parse XML output (basic implementation)\n",
    "    for line in result.stderr.split(\"\\n\"):\n",
    "        if \"<error \" in line:\n",
    "            error_type = line.split('id=\"')[1].split('\"')[0]\n",
    "            severity = line.split('severity=\"')[1].split('\"')[0]\n",
    "            message = line.split('msg=\"')[1].split('\"')[0]\n",
    "            cppcheck_data.append({\n",
    "                \"file_index\": i,\n",
    "                \"error_type\": error_type,\n",
    "                \"severity\": severity,\n",
    "                \"message\": message\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for CppCheck findings\n",
    "df_cppcheck = pd.DataFrame(cppcheck_data)\n",
    "\n",
    "# Aggregate security findings back into the main DataFrame\n",
    "df[\"security_findings\"] = df_cppcheck.groupby(\"file_index\")[\"error_type\"].apply(list)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"test_code_metrics_with_cppcheck.csv\", index=False)\n",
    "print(\"Security findings extracted and saved as 'test_code_metrics_with_cppcheck.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2449f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing code with CppCheck:   0%|                    | 0/2732 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'temp_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m cppcheck_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing code with CppCheck\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Save each input_text to a temporary .c file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(temp_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prepare for CppCheck Analysis\n",
    "cppcheck_data = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing code with CppCheck\"):\n",
    "    # Save each input_text to a temporary .c file\n",
    "    file_path = os.path.join(temp_dir, f\"snippet_{i}.c\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(row[\"input_text\"])\n",
    "    \n",
    "    # Run CppCheck on the file\n",
    "    result = subprocess.run(\n",
    "        [\"cppcheck\", \"--enable=all\", \"--xml\", file_path],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Parse XML output (basic implementation)\n",
    "    for line in result.stderr.split(\"\\n\"):\n",
    "        if \"<error \" in line:\n",
    "            error_type = line.split('id=\"')[1].split('\"')[0]\n",
    "            severity = line.split('severity=\"')[1].split('\"')[0]\n",
    "            message = line.split('msg=\"')[1].split('\"')[0]\n",
    "            cppcheck_data.append({\n",
    "                \"file_index\": i,\n",
    "                \"error_type\": error_type,\n",
    "                \"severity\": severity,\n",
    "                \"message\": message\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for CppCheck findings\n",
    "df_cppcheck = pd.DataFrame(cppcheck_data)\n",
    "\n",
    "# Aggregate security findings back into the main DataFrame\n",
    "df[\"security_findings\"] = df_cppcheck.groupby(\"file_index\")[\"error_type\"].apply(list)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"test_code_metrics_with_cppcheck.csv\", index=False)\n",
    "print(\"Security findings extracted and saved as 'test_code_metrics_with_cppcheck.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebe602ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[syntaxError, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[syntaxError, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[syntaxError, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unusedFunction, checkersReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[syntaxError, checkersReport]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...   \n",
       "...                                                 ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...   \n",
       "\n",
       "      cyclomatic_complexity  lines_of_code  function_count  import_count  \\\n",
       "0                       7.0           53.0             NaN           NaN   \n",
       "1                       1.0            9.0             NaN           NaN   \n",
       "2                       0.0           22.0             NaN           NaN   \n",
       "3                       3.0           27.0             NaN           NaN   \n",
       "4                       0.0           23.0             NaN           NaN   \n",
       "...                     ...            ...             ...           ...   \n",
       "2727                    0.0           18.0             NaN           NaN   \n",
       "2728                    1.0           13.0             NaN           NaN   \n",
       "2729                    3.0           35.0             NaN           NaN   \n",
       "2730                    4.0           31.0             NaN           NaN   \n",
       "2731                    0.0           14.0             NaN           NaN   \n",
       "\n",
       "      variable_count  comment_density                 security_findings  \n",
       "0                NaN              NaN  [unusedFunction, checkersReport]  \n",
       "1                NaN              NaN  [unusedFunction, checkersReport]  \n",
       "2                NaN              NaN     [syntaxError, checkersReport]  \n",
       "3                NaN              NaN  [unusedFunction, checkersReport]  \n",
       "4                NaN              NaN     [syntaxError, checkersReport]  \n",
       "...              ...              ...                               ...  \n",
       "2727             NaN              NaN     [syntaxError, checkersReport]  \n",
       "2728             NaN              NaN  [unusedFunction, checkersReport]  \n",
       "2729             NaN              NaN  [unusedFunction, checkersReport]  \n",
       "2730             NaN              NaN  [unusedFunction, checkersReport]  \n",
       "2731             NaN              NaN     [syntaxError, checkersReport]  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1459ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking syntax with Cppcheck: 100%|| 2732/2732 [00:21<00:00, 130.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax errors saved to 'syntax_errors.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "# Load the test dataset\n",
    "df = pd.read_csv(\"test_code_metrics.csv\")  # Ensure this file exists\n",
    "\n",
    "# Directory for temporary files\n",
    "temp_dir = \"./temp_code_files\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store syntax error information\n",
    "syntax_errors = []\n",
    "\n",
    "# Analyze code snippets with Cppcheck\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking syntax with Cppcheck\"):\n",
    "    file_path = os.path.join(temp_dir, f\"snippet_{i}.c\")\n",
    "    \n",
    "    # Save each input_text to a temporary .c file\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(row[\"input_text\"])\n",
    "    \n",
    "    # Run Cppcheck and capture output\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"cppcheck\", file_path, \"--enable=syntax\"],\n",
    "            stderr=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        error_output = result.stderr\n",
    "        if \"error:\" in error_output or \"warning:\" in error_output:\n",
    "            syntax_errors.append({\"index\": i, \"error\": error_output.strip()})\n",
    "    except Exception as e:\n",
    "        syntax_errors.append({\"index\": i, \"error\": str(e)})\n",
    "\n",
    "# Save syntax errors for review\n",
    "df_errors = pd.DataFrame(syntax_errors)\n",
    "df_errors.to_csv(\"syntax_errors.csv\", index=False)\n",
    "print(\"Syntax errors saved to 'syntax_errors.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5462805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_9354/1958624972.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing code snippets with Cppcheck...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Cppcheck: 100%|| 2732/2732 [00:35<00:00, 76.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with Cppcheck metrics saved as 'test_code_metrics_with_cppcheck.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Step 1: Load the fine-tuned model tokenizer\n",
    "model_name = \"./improved_finetuned_codebert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Step 2: Load the test dataset\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "test_texts = [tokenizer.decode(entry[\"input_ids\"], skip_special_tokens=True) for entry in test_data]\n",
    "\n",
    "# Step 3: Create a DataFrame for analysis\n",
    "df = pd.DataFrame({\"input_text\": test_texts})\n",
    "\n",
    "# Directory for temporary files (code snippets from the DataFrame)\n",
    "temp_dir = \"./temp_code_files\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Initialize columns for Cppcheck metrics\n",
    "metrics = {\n",
    "    \"syntax_error\": [],\n",
    "    \"memory_leak\": [],\n",
    "    \"complexity_warning\": [],\n",
    "    \"performance_issue\": [],\n",
    "    \"thread_safety_issue\": [],\n",
    "    \"out_of_bounds_access\": [],\n",
    "    \"null_pointer_dereference\": [],\n",
    "}\n",
    "\n",
    "# Step 4: Analyze each code snippet with Cppcheck\n",
    "print(\"Analyzing code snippets with Cppcheck...\")\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Running Cppcheck\"):\n",
    "    # Save each input_text to a temporary .c file\n",
    "    file_path = os.path.join(temp_dir, f\"snippet_{i}.c\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(row[\"input_text\"])\n",
    "    \n",
    "    # Run Cppcheck on the file\n",
    "    cppcheck_output = subprocess.run(\n",
    "        [\"cppcheck\", \"--enable=all\", \"--quiet\", \"--template={file}:{line}:{message}\", file_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # Parse the output for specific issues\n",
    "    output_lines = cppcheck_output.stderr.splitlines()\n",
    "    syntax_error = any(\"syntax error\" in line.lower() for line in output_lines)\n",
    "    memory_leak = any(\"memory leak\" in line.lower() for line in output_lines)\n",
    "    complexity_warning = any(\"too complex\" in line.lower() for line in output_lines)\n",
    "    performance_issue = any(\"performance\" in line.lower() for line in output_lines)\n",
    "    thread_safety_issue = any(\"thread\" in line.lower() for line in output_lines)\n",
    "    out_of_bounds_access = any(\"out of bounds\" in line.lower() for line in output_lines)\n",
    "    null_pointer_dereference = any(\"null pointer\" in line.lower() for line in output_lines)\n",
    "    \n",
    "    # Append results to metrics\n",
    "    metrics[\"syntax_error\"].append(syntax_error)\n",
    "    metrics[\"memory_leak\"].append(memory_leak)\n",
    "    metrics[\"complexity_warning\"].append(complexity_warning)\n",
    "    metrics[\"performance_issue\"].append(performance_issue)\n",
    "    metrics[\"thread_safety_issue\"].append(thread_safety_issue)\n",
    "    metrics[\"out_of_bounds_access\"].append(out_of_bounds_access)\n",
    "    metrics[\"null_pointer_dereference\"].append(null_pointer_dereference)\n",
    "\n",
    "# Step 5: Add metrics to the DataFrame\n",
    "for metric, values in metrics.items():\n",
    "    df[metric] = values\n",
    "\n",
    "# Step 6: Save the updated DataFrame\n",
    "df.to_csv(\"test_code_metrics_with_cppcheck.csv\", index=False)\n",
    "print(\"Updated dataset with Cppcheck metrics saved as 'test_code_metrics_with_cppcheck.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3bd4346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>syntax_error</th>\n",
       "      <th>memory_leak</th>\n",
       "      <th>complexity_warning</th>\n",
       "      <th>performance_issue</th>\n",
       "      <th>thread_safety_issue</th>\n",
       "      <th>out_of_bounds_access</th>\n",
       "      <th>null_pointer_dereference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  syntax_error  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...         False   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...         False   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...         False   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...         False   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...         False   \n",
       "...                                                 ...           ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...         False   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...         False   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...         False   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...         False   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...         False   \n",
       "\n",
       "      memory_leak  complexity_warning  performance_issue  thread_safety_issue  \\\n",
       "0           False               False              False                False   \n",
       "1           False               False              False                False   \n",
       "2           False               False              False                False   \n",
       "3           False               False              False                False   \n",
       "4           False               False              False                False   \n",
       "...           ...                 ...                ...                  ...   \n",
       "2727        False               False              False                False   \n",
       "2728        False               False              False                False   \n",
       "2729        False               False              False                False   \n",
       "2730        False               False              False                False   \n",
       "2731        False               False              False                False   \n",
       "\n",
       "      out_of_bounds_access  null_pointer_dereference  \n",
       "0                    False                     False  \n",
       "1                    False                     False  \n",
       "2                    False                     False  \n",
       "3                    False                     False  \n",
       "4                    False                     False  \n",
       "...                    ...                       ...  \n",
       "2727                 False                     False  \n",
       "2728                 False                     False  \n",
       "2729                 False                     False  \n",
       "2730                 False                     False  \n",
       "2731                 False                     False  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95df0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...   \n",
       "...                                                 ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...   \n",
       "\n",
       "      cyclomatic_complexity  lines_of_code  function_count  import_count  \\\n",
       "0                       7.0           53.0             NaN           NaN   \n",
       "1                       1.0            9.0             NaN           NaN   \n",
       "2                       0.0           22.0             NaN           NaN   \n",
       "3                       3.0           27.0             NaN           NaN   \n",
       "4                       0.0           23.0             NaN           NaN   \n",
       "...                     ...            ...             ...           ...   \n",
       "2727                    0.0           18.0             NaN           NaN   \n",
       "2728                    1.0           13.0             NaN           NaN   \n",
       "2729                    3.0           35.0             NaN           NaN   \n",
       "2730                    4.0           31.0             NaN           NaN   \n",
       "2731                    0.0           14.0             NaN           NaN   \n",
       "\n",
       "      variable_count  comment_density  security_findings  \n",
       "0                NaN              NaN                NaN  \n",
       "1                NaN              NaN                NaN  \n",
       "2                NaN              NaN                NaN  \n",
       "3                NaN              NaN                NaN  \n",
       "4                NaN              NaN                NaN  \n",
       "...              ...              ...                ...  \n",
       "2727             NaN              NaN                NaN  \n",
       "2728             NaN              NaN                NaN  \n",
       "2729             NaN              NaN                NaN  \n",
       "2730             NaN              NaN                NaN  \n",
       "2731             NaN              NaN                NaN  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.read_csv(\"test_code_metrics_with_validation.csv\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8ba60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation for cyclomatic_complexity:\n",
      "  Pearson Correlation: -0.019182794497793282\n",
      "  Pearson P-value: 0.31620356186600795\n",
      "  Spearman Correlation: -0.02942718228227836\n",
      "  Spearman P-value: 0.1241110056698874\n",
      "\n",
      "Correlation for lines_of_code:\n",
      "  Pearson Correlation: 0.02812357702691371\n",
      "  Pearson P-value: 0.14167115380854928\n",
      "  Spearman Correlation: 0.042506769945123035\n",
      "  Spearman P-value: 0.026299930078721438\n",
      "\n",
      "Correlation for syntax_error:\n",
      "  Pearson Correlation: 0.03748797834814889\n",
      "  Pearson P-value: 0.05008541945564956\n",
      "  Spearman Correlation: 0.03748797834814913\n",
      "  Spearman P-value: 0.0500854194556492\n",
      "Updated dataset saved as 'test_code_metrics_with_failure.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_13057/1627044611.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Step 1: Load datasets\n",
    "metrics_df = pd.read_csv(\"test_code_metrics_with_validation.csv\")  # Metrics dataset\n",
    "predictions_df = pd.read_csv(\"test_predictions_with_confidence.csv\")  # Predictions dataset\n",
    "\n",
    "# Step 2: Add `predicted_label` column to metrics_df\n",
    "metrics_df[\"predicted_label\"] = predictions_df[\"predicted_label\"]\n",
    "\n",
    "# Step 3: Load the tokenized test data and add true labels\n",
    "test_data = torch.load(\"tokenized_test.pt\")  # Ensure this file exists\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels\n",
    "metrics_df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 4: Add Correctness and Failure columns\n",
    "metrics_df[\"is_correct\"] = metrics_df[\"predicted_label\"] == metrics_df[\"true_label\"]\n",
    "metrics_df[\"is_failure\"] = ~metrics_df[\"is_correct\"]\n",
    "\n",
    "# Step 5: Define a function to calculate correlations\n",
    "def compute_correlation(variable, target):\n",
    "    pearson_corr, pearson_p = pearsonr(metrics_df[variable], metrics_df[target])\n",
    "    spearman_corr, spearman_p = spearmanr(metrics_df[variable], metrics_df[target])\n",
    "    return {\n",
    "        \"Pearson Correlation\": pearson_corr,\n",
    "        \"Pearson P-value\": pearson_p,\n",
    "        \"Spearman Correlation\": spearman_corr,\n",
    "        \"Spearman P-value\": spearman_p\n",
    "    }\n",
    "\n",
    "# Step 6: Compute correlations\n",
    "correlation_results = {}\n",
    "for variable in [\"cyclomatic_complexity\", \"lines_of_code\"]:\n",
    "    if variable in metrics_df.columns:\n",
    "        correlation_results[variable] = compute_correlation(variable, \"is_failure\")\n",
    "\n",
    "# Step 7: Compute correlation for syntax errors\n",
    "metrics_df[\"has_syntax_error\"] = metrics_df[\"cyclomatic_complexity\"] == 0  # Records with 0 have syntax errors\n",
    "correlation_results[\"syntax_error\"] = compute_correlation(\"has_syntax_error\", \"is_failure\")\n",
    "\n",
    "# Display results\n",
    "for variable, results in correlation_results.items():\n",
    "    print(f\"\\nCorrelation for {variable}:\")\n",
    "    for metric, value in results.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Step 8: Save updated metrics_df with new columns\n",
    "metrics_df.to_csv(\"test_code_metrics_with_failure.csv\", index=False)\n",
    "print(\"Updated dataset saved as 'test_code_metrics_with_failure.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62cc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/h6tflr0135gbw70c3f02x1qm0000gq/T/ipykernel_13057/2106452032.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"tokenized_test.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load test_predictions_with_confidence.csv to get predicted_label\n",
    "predictions_df = pd.read_csv(\"test_predictions_with_confidence.csv\")\n",
    "metrics_df = pd.read_csv(\"test_code_metrics_with_validation.csv\")\n",
    "\n",
    "# Step 2: Merge predicted_label into metrics_df\n",
    "metrics_df = metrics_df.merge(predictions_df[[\"predicted_label\"]], left_index=True, right_index=True)\n",
    "\n",
    "# Step 3: Load tokenized test data to extract true labels\n",
    "test_data = torch.load(\"tokenized_test.pt\")\n",
    "true_labels = [entry[\"label\"] for entry in test_data]  # Extract true labels\n",
    "metrics_df[\"true_label\"] = true_labels\n",
    "\n",
    "# Step 4: Calculate is_correct and is_failure\n",
    "metrics_df[\"is_correct\"] = metrics_df[\"predicted_label\"] == metrics_df[\"true_label\"]\n",
    "metrics_df[\"is_failure\"] = ~metrics_df[\"is_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1c7826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature  Pearson Correlation  Pearson P-value  \\\n",
      "0  interaction_term            -0.009207         0.630504   \n",
      "1        ratio_term            -0.043839         0.021939   \n",
      "\n",
      "   Spearman Correlation  Spearman P-value  \n",
      "0             -0.023635          0.216833  \n",
      "1             -0.045329          0.017815  \n"
     ]
    }
   ],
   "source": [
    "# Create interaction terms\n",
    "metrics_df[\"interaction_term\"] = metrics_df[\"cyclomatic_complexity\"] * metrics_df[\"lines_of_code\"]\n",
    "metrics_df[\"ratio_term\"] = metrics_df[\"cyclomatic_complexity\"] / (metrics_df[\"lines_of_code\"] + 1e-9)\n",
    "\n",
    "# Correlation Analysis\n",
    "def compute_correlation(df, feature, target=\"is_failure\"):\n",
    "    pearson_corr, pearson_p = pearsonr(df[feature], df[target])\n",
    "    spearman_corr, spearman_p = spearmanr(df[feature], df[target])\n",
    "    return {\n",
    "        \"Feature\": feature,\n",
    "        \"Pearson Correlation\": pearson_corr,\n",
    "        \"Pearson P-value\": pearson_p,\n",
    "        \"Spearman Correlation\": spearman_corr,\n",
    "        \"Spearman P-value\": spearman_p,\n",
    "    }\n",
    "\n",
    "# Perform correlation analysis for interaction terms\n",
    "features_to_test = [\"interaction_term\", \"ratio_term\"]\n",
    "results = [compute_correlation(metrics_df, feature) for feature in features_to_test]\n",
    "\n",
    "# Display Results\n",
    "correlation_results = pd.DataFrame(results)\n",
    "print(correlation_results)\n",
    "\n",
    "# Save the results if needed\n",
    "correlation_results.to_csv(\"interaction_term_correlation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c575ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>cyclomatic_complexity</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>function_count</th>\n",
       "      <th>import_count</th>\n",
       "      <th>variable_count</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>security_findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static void decode_mclms(WmallDecodeCtx *s)\\n\\...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static int qcow2_change_backing_file(BlockDriv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static void simple_whitespace(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>static void pred8x8_top_dc_rv40_c(uint8_t *src...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static int32_t bmdma_prepare_buf(IDEDMA *dma, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>static void pc_compat_1_4(QEMUMachineInitArgs ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>PCIDevice *pci_nic_init(NICInfo *nd, const cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>int ff_h264_alloc_tables(H264Context *h){\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2732 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "0     static void decode_mclms(WmallDecodeCtx *s)\\n\\...   \n",
       "1     static int qcow2_change_backing_file(BlockDriv...   \n",
       "2     static void simple_whitespace(void)\\n\\n{\\n\\n  ...   \n",
       "3     static void pred8x8_top_dc_rv40_c(uint8_t *src...   \n",
       "4     static int32_t bmdma_prepare_buf(IDEDMA *dma, ...   \n",
       "...                                                 ...   \n",
       "2727  static void FUNC(put_hevc_epel_bi_w_h)(uint8_t...   \n",
       "2728  static void pc_compat_1_4(QEMUMachineInitArgs ...   \n",
       "2729  PCIDevice *pci_nic_init(NICInfo *nd, const cha...   \n",
       "2730  static void gen_exts(int ot, TCGv reg)\\n\\n{\\n\\...   \n",
       "2731  int ff_h264_alloc_tables(H264Context *h){\\n\\n ...   \n",
       "\n",
       "      cyclomatic_complexity  lines_of_code  function_count  import_count  \\\n",
       "0                       7.0           53.0             NaN           NaN   \n",
       "1                       1.0            9.0             NaN           NaN   \n",
       "2                       0.0           22.0             NaN           NaN   \n",
       "3                       3.0           27.0             NaN           NaN   \n",
       "4                       0.0           23.0             NaN           NaN   \n",
       "...                     ...            ...             ...           ...   \n",
       "2727                    0.0           18.0             NaN           NaN   \n",
       "2728                    1.0           13.0             NaN           NaN   \n",
       "2729                    3.0           35.0             NaN           NaN   \n",
       "2730                    4.0           31.0             NaN           NaN   \n",
       "2731                    0.0           14.0             NaN           NaN   \n",
       "\n",
       "      variable_count  comment_density  security_findings  \n",
       "0                NaN              NaN                NaN  \n",
       "1                NaN              NaN                NaN  \n",
       "2                NaN              NaN                NaN  \n",
       "3                NaN              NaN                NaN  \n",
       "4                NaN              NaN                NaN  \n",
       "...              ...              ...                ...  \n",
       "2727             NaN              NaN                NaN  \n",
       "2728             NaN              NaN                NaN  \n",
       "2729             NaN              NaN                NaN  \n",
       "2730             NaN              NaN                NaN  \n",
       "2731             NaN              NaN                NaN  \n",
       "\n",
       "[2732 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff811a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson Correlation': 0.03748797834814889,\n",
       " 'Pearson P-value': 0.05008541945564956,\n",
       " 'Spearman Correlation': 0.03748797834814913,\n",
       " 'Spearman P-value': 0.0500854194556492}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997173f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cyclomatic_complexity': {'Pearson Correlation': -0.019182794497793282,\n",
       "  'Pearson P-value': 0.31620356186600795,\n",
       "  'Spearman Correlation': -0.02942718228227836,\n",
       "  'Spearman P-value': 0.1241110056698874},\n",
       " 'lines_of_code': {'Pearson Correlation': 0.02812357702691371,\n",
       "  'Pearson P-value': 0.14167115380854928,\n",
       "  'Spearman Correlation': 0.042506769945123035,\n",
       "  'Spearman P-value': 0.026299930078721438},\n",
       " 'syntax_error': {'Pearson Correlation': 0.03748797834814889,\n",
       "  'Pearson P-value': 0.05008541945564956,\n",
       "  'Spearman Correlation': 0.03748797834814913,\n",
       "  'Spearman P-value': 0.0500854194556492}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81862172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
